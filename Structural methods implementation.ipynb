{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run load_data.py\n",
    "import sys\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import scipy.sparse.linalg as splin\n",
    "import scipy.sparse as sparse\n",
    "import random\n",
    "import math\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this document the methods described in the methods section are implemented for the network of verdicts. The data is loaded as `networkx`directed graph making it relatively easy to work with. The goal is to set up an easily used interface for running K-folds cross validation on the network for different link prediction algorithms and evaluate them with ROC and precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the greatest connected component and work on that\n",
    "components = []\n",
    "lengths = []\n",
    "# Find the greatest component from the undirected version of the graph\n",
    "for component in nx.connected_component_subgraphs(nx.Graph(G)):\n",
    "    components.append(component)\n",
    "    lengths.append(len(component))\n",
    "# Find the GCC as the largest component and then recreate the directed graph\n",
    "GCC = components[lengths.index(max(lengths))]\n",
    "GCC = G.subgraph(GCC.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def jaccard(validation_set, G):\n",
    "    \"\"\"\n",
    "    Perform Jaccard scoring on a single edge\n",
    "    \n",
    "    arguments:\n",
    "    non_edge -- edge tuple specified by node endpoints\n",
    "    G -- graph containing the nodes in the edge\n",
    "    \n",
    "    return:\n",
    "    edges with the score as an attribute\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        u = set(G.neighbors(non_edge[0]))\n",
    "        v = set(G.neighbors(non_edge[1]))\n",
    "        uv_un = len(u.union(v))\n",
    "        uv_int = len(u.intersection(v))\n",
    "        if uv_int == 0 or uv_un == 0:\n",
    "            s= 0.0\n",
    "        else:\n",
    "            s = (1.0*uv_int)/uv_un\n",
    "        results.append(non_edge + ({'score': s},))\n",
    "    return results\n",
    "    \n",
    "def common_neighbors(validation_set, G):\n",
    "    \"\"\"\n",
    "    Perform common neighbors scoring on a single edge\n",
    "    \n",
    "    arguments:\n",
    "    non_edge -- edge tuple specified by node endpoints\n",
    "    G -- graph containing the nodes in the edge\n",
    "    \n",
    "    return:\n",
    "    edges with the score as an attribute\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        u = set(G.neighbors(non_edge[0]))\n",
    "        v = set(G.neighbors(non_edge[1]))\n",
    "        s = len(u.intersection(v))\n",
    "        results.append(non_edge + ({'score': s},))\n",
    "    return results\n",
    "\n",
    "def adamic_adar(validation_set, G):\n",
    "    \"\"\"\n",
    "    Perform Adamic/Adar scoring on a single edge\n",
    "    \n",
    "    arguments:\n",
    "    non_edge -- edge tuple specified by node endpoints\n",
    "    G -- graph containing the nodes in the edge\n",
    "    \n",
    "    return:\n",
    "    edges with the score as an attribute\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        u = set(G.neighbors(non_edge[0]))\n",
    "        v = set(G.neighbors(non_edge[1]))\n",
    "        uv_int = u.intersection(v)\n",
    "        s = sum([1.0/math.log(G.degree(node)) for node in uv_int if G.degree(node) != 1 and G.degree(node) != 0])\n",
    "        results.append(non_edge + ({'score': s},))\n",
    "    return results\n",
    "\n",
    "def resource_allocation(validation_set, G):\n",
    "    \"\"\"\n",
    "    Perform resource allocation scoring on a single edge\n",
    "    \n",
    "    arguments:\n",
    "    non_edge -- edge tuple specified by node endpoints\n",
    "    G -- graph containing the nodes in the edge\n",
    "    \n",
    "    return:\n",
    "    edges with the score as an attribute\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        u = set(G.neighbors(non_edge[0]))\n",
    "        v = set(G.neighbors(non_edge[1]))\n",
    "        uv_int = u.intersection(v)\n",
    "        s = sum([1.0/G.degree(node) for node in uv_int if G.degree(node) != 0])\n",
    "        results.append(non_edge + ({'score': s},))\n",
    "    return results\n",
    "\n",
    "def leicht_holme_newman(validation_set, G):\n",
    "    \"\"\"\n",
    "    Perform LHN1 scoring on a single edge\n",
    "    \n",
    "    arguments:\n",
    "    non_edge -- edge tuple specified by node endpoints\n",
    "    G -- graph containing the nodes in the edge\n",
    "    \n",
    "    return:\n",
    "    edges with the score as an attribute\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        u = set(G.neighbors(non_edge[0]))\n",
    "        v = set(G.neighbors(non_edge[1]))\n",
    "        uv_int = len(u.intersection(v))\n",
    "        if G.degree(non_edge[0]) == 0 or G.degree(non_edge[1]) == 0:\n",
    "            s = 0.0\n",
    "        else:\n",
    "            s = (uv_int/G.degree(non_edge[0])*G.degree(non_edge[1]))\n",
    "        results.append(non_edge + ({'score': s},))\n",
    "    return results\n",
    "\n",
    "def sorensen(validation_set, G):\n",
    "    \"\"\"\n",
    "    Perform SÃ¸rensen index scoring on a single edge\n",
    "    \n",
    "    arguments:\n",
    "    non_edge -- edge tuple specified by node endpoints\n",
    "    G -- graph containing the nodes in the edge\n",
    "    \n",
    "    return:\n",
    "    edges with the score as an attribute\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        u = set(G.neighbors(non_edge[0]))\n",
    "        v = set(G.neighbors(non_edge[1]))\n",
    "        uv_int = len(u.intersection(v))\n",
    "        if G.degree(non_edge[0]) == 0 and G.degree(non_edge[1]) == 0:\n",
    "            s = 0.0\n",
    "        else:\n",
    "            s = 2*uv_int/(G.degree(non_edge[0])+G.degree(non_edge[1]))\n",
    "        results.append(non_edge + ({'score': s},))\n",
    "    return results\n",
    "\n",
    "def hub_promoted(validation_set, G):\n",
    "    \"\"\"\n",
    "    Perform hub promoted index scoring on a single edge\n",
    "    \n",
    "    arguments:\n",
    "    non_edge -- edge tuple specified by node endpoints\n",
    "    G -- graph containing the nodes in the edge\n",
    "    \n",
    "    return:\n",
    "    edges with the score as an attribute\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        u = set(G.neighbors(non_edge[0]))\n",
    "        v = set(G.neighbors(non_edge[1]))\n",
    "        uv_int = len(u.intersection(v))\n",
    "        if G.degree(non_edge[0]) == 0 and G.degree(non_edge[1]) == 0:\n",
    "            s = 0.0\n",
    "        else:\n",
    "            s = uv_int/max(G.degree(non_edge[0]), G.degree(non_edge[1]))\n",
    "        results.append(non_edge + ({'score': s},))\n",
    "    return results\n",
    "\n",
    "def hub_depressed(validation_set, G):\n",
    "    \"\"\"\n",
    "    Perform hub promoted index scoring on a single edge\n",
    "    \n",
    "    arguments:\n",
    "    non_edge -- edge tuple specified by node endpoints\n",
    "    G -- graph containing the nodes in the edge\n",
    "    \n",
    "    return:\n",
    "    edges with the score as an attribute\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        u = set(G.neighbors(non_edge[0]))\n",
    "        v = set(G.neighbors(non_edge[1]))\n",
    "        uv_int = len(u.intersection(v))\n",
    "        if G.degree(non_edge[0]) == 0 or G.degree(non_edge[1]) == 0:\n",
    "            s = 0.0\n",
    "        else:\n",
    "            s = uv_int/min(G.degree(non_edge[0]), G.degree(non_edge[1]))\n",
    "        results.append(non_edge + ({'score': s},))\n",
    "    return results\n",
    "\n",
    "def salton(validation_set, G):\n",
    "    \"\"\"\n",
    "    Perform Salton index scoring on a single edge\n",
    "    \n",
    "    arguments:\n",
    "    non_edge -- edge tuple specified by node endpoints\n",
    "    G -- graph containing the nodes in the edge\n",
    "    \n",
    "    return:\n",
    "    edges with the score as an attribute\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        u = set(G.neighbors(non_edge[0]))\n",
    "        v = set(G.neighbors(non_edge[1]))\n",
    "        uv_int = len(u.intersection(v))\n",
    "        if G.degree(non_edge[0]) == 0 or G.degree(non_edge[1]) == 0:\n",
    "            s = 0.0\n",
    "        else:\n",
    "            s = uv_int/math.sqrt(G.degree(non_edge[0])*G.degree(non_edge[1]))\n",
    "        results.append(non_edge + ({'score': s},))\n",
    "    return results\n",
    "\n",
    "def preferential_attachment(validation_set, G):\n",
    "    \"\"\"\n",
    "    Perform preferential attachment scoring on a single edge\n",
    "    \n",
    "    arguments:\n",
    "    non_edge -- edge tuple specified by node endpoints\n",
    "    G -- graph containing the nodes in the edge\n",
    "    \n",
    "    return:\n",
    "    edges with the score as an attribute\n",
    "    \"\"\"\n",
    "    \n",
    "    return [non_edge + ({'score': G.degree(non_edge[0])*G.degree(non_edge[1])},) for non_edge in validation_set]\n",
    "\n",
    "## Global index similarities, computed based on every path between two nodes. SLower than local indices but contain full\n",
    "## information\n",
    "def katz_index(validation_set, G, beta):\n",
    "    \"\"\"\n",
    "    Return a weighted sum over every path between two nodes, s_xy = sum(beta*A+beta^2*A^2+...) = (I-beta*A^(-1))-I\n",
    "    \n",
    "    arguments:\n",
    "    validation_set -- set of edges between nodes to be considered\n",
    "    A_inv -- Precomputed inverse of the adjacency matrix\n",
    "    beta -- weighting parameter, the smaller it is the closer the result is to CN\n",
    "    \n",
    "    return:\n",
    "    list of edges with the score as an attribute\n",
    "    \"\"\"\n",
    "    A = nx.adjacency_matrix(G)\n",
    "    # Create indices to access A\n",
    "    id_to_ind = {node: i for (i, node) in zip(range(0, len(G.nodes())), G.nodes())}\n",
    "    max_eig = splin.eigsh(A.asfptype(), k=1, which='LM', return_eigenvectors=False)[0]\n",
    "    if 1.0/max_eig <= beta:\n",
    "        raise Exception(\"Beta must be less than or equal to the maximum eigenvalue of A(G), which is: {}\".format(1.0/max_eig))\n",
    "    \n",
    "    I = np.identity(A.shape[0])\n",
    "    S = np.linalg.inv(I-beta*A.todense()) - I\n",
    "    results = [(x,y, {'score': S[id_to_ind[x], id_to_ind[y]]}) for (x,y) in validation_set]\n",
    "    return results\n",
    "\n",
    "def leicht_holme_newman_global(validation_set, G, alpha):\n",
    "    \"\"\"\n",
    "    Return a weighted sum of every path between two nodes, s_xy = sum(I+omega*A+omega^2*A^2+...)\n",
    "    \"\"\"\n",
    "    A = nx.adjacency_matrix(G)\n",
    "    # Create indices to access A\n",
    "    id_to_ind = {node: i for (i, node) in zip(range(0, len(G.nodes())), G.nodes())}\n",
    "    M = len(G.edges())\n",
    "    max_eig = splin.eigsh(A.asfptype(), k=1, which='LM', return_eigenvectors=False)[0]\n",
    "    I = np.identity(A.shape[0])\n",
    "    D_inv = np.linalg.inv(I+np.diag(G.degree().values())) # TODO: This normally does not have the I factor, but this is done to remove 0-rows creating singular matrices\n",
    "    A_inv=np.linalg.inv((I-alpha*A)/max_eig)\n",
    "    S = 2*M*max_eig*D_inv*A_inv*D_inv\n",
    "    results = [(x,y, {'score': S[id_to_ind[x], id_to_ind[y]]}) for (x,y) in validation_set]\n",
    "    return results\n",
    "\n",
    "def average_commute_time(validation_set, G):\n",
    "    \"\"\"\n",
    "    Return the score as the inverse of the average commute time between two nodes, found as the pseudo inverse of the Laplacian\n",
    "    \"\"\"\n",
    "    A = nx.adjacency_matrix(G)\n",
    "    # Create indices to access A\n",
    "    id_to_ind = {node: i for (i, node) in zip(range(0, len(G.nodes())), G.nodes())}\n",
    "    L_plus = np.linalg.pinv(nx.laplacian_matrix(G).todense())\n",
    "    results = []\n",
    "    scoring = lambda x,y: 1.0/(L_plus[id_to_ind[x], id_to_ind[x]] + L_plus[id_to_ind[y], id_to_ind[y]] - 2*L_plus[id_to_ind[x], id_to_ind[y]])\n",
    "    for x,y in validation_set:\n",
    "        results.append((x,y, {'score': scoring(x,y)}))\n",
    "    return results\n",
    "\n",
    "def local_path_index(validation_set, G, epsilon, n):\n",
    "    \"\"\"\n",
    "    The same as the katz index, but constricted to paths of length n\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for x,y in validation_set:\n",
    "        count = [0 for _ in range(0, n+1)]\n",
    "        q = [(x, 0)]\n",
    "        while len(q) != 0:\n",
    "            v, dist = q.pop()\n",
    "            for w in G.neighbors(v):\n",
    "                if dist < (n-1):\n",
    "                    q.append((w, dist + 1))\n",
    "                if dist < n and w == y:\n",
    "                    count[dist] += 1\n",
    "        s = sum([math.pow(epsilon,1.0*i)*c for i, c in zip(range(0, len(count) + 1), count)])\n",
    "        results.append((x,y, {'score': s}))\n",
    "    return results\n",
    "\n",
    "def local_path_index2(validation_set, G, epsilon, n):\n",
    "    \"\"\"\n",
    "    The same as the katz index, but constricted to paths of length n\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for x,y in validation_set:\n",
    "        s = 0.0\n",
    "        neighborhood = set(G.neighbors(x))\n",
    "        for i in range(2, n+2):\n",
    "            if y in neighborhood:\n",
    "                H = G.subgraph(neighborhood)\n",
    "                id_to_ind = {node: i for (i, node) in zip(range(0, len(H.nodes())), H.nodes())}\n",
    "                A = np.linalg.matrix_power(nx.adjacency_matrix(H).todense(), i)\n",
    "                s += math.pow(epsilon, i-2)*A[id_to_ind[x], id_to_ind[y]]\n",
    "            \n",
    "            for neighbor in list(neighborhood):\n",
    "                neighborhood.update(set(G.neighbors(neighbor)))\n",
    "        results.append((x,y,{'score': s}))\n",
    "    return results\n",
    "\n",
    "def local_random_walk(validation_set, G, t):\n",
    "    \"\"\"\n",
    "    \n",
    "    arguments:\n",
    "    validation_set -- set of edges between nodes to be considered\n",
    "    G -- the graph the validation set is evaluated against\n",
    "    n -- number of steps to be considered\n",
    "    \n",
    "    return:\n",
    "    list of edges with the score as an attribute\n",
    "    \"\"\"\n",
    "    for x,y in validation_set:\n",
    "        pi_xy = 0\n",
    "        pi_yx = 0\n",
    "        for tau in range(1, t+1):\n",
    "            d_x = 0\n",
    "\n",
    "def k_fold_validate(G, k, fun, **kwargs):\n",
    "    \"\"\"\n",
    "    K-fold validation of some specified function\n",
    "    \n",
    "    arguments:\n",
    "    G -- Graph to perform the function on\n",
    "    k -- number of folds\n",
    "    fun -- function to be evaluated\n",
    "    kwargs -- arguments to be passed to the evaluated function\n",
    "    \n",
    "    return:\n",
    "    List of lists of scored predictions\n",
    "    \"\"\"\n",
    "    G_undirected = nx.Graph(G)\n",
    "    edges = G_undirected.edges()\n",
    "    random.shuffle(edges)\n",
    "    N = len(edges)/k\n",
    "    validation_sets = []\n",
    "    for i in range(0,k):\n",
    "        validation_sets.append(set(edges[i*N:(i+1)*N]))\n",
    "    results = []\n",
    "    for true_validation_set in validation_sets:\n",
    "        G_train = G_undirected.copy()\n",
    "        G_train.remove_edges_from(true_validation_set)\n",
    "        count = 0\n",
    "        false_validation_set = set()\n",
    "        for edge in nx.non_edges(G_train):\n",
    "            if count >= N:\n",
    "                break\n",
    "            false_validation_set.add(edge)\n",
    "            count = count + 1\n",
    "        validation_set = true_validation_set.union(false_validation_set)\n",
    "        results.append(fun(validation_set, G_train, **kwargs))\n",
    "    return results\n",
    "\n",
    "def precision(G, results, L):\n",
    "    \"\"\"\n",
    "    Find the ratio of the true positives to trues\n",
    "    \n",
    "    arguments:\n",
    "    G -- graph the results are based on\n",
    "    results -- list of lists of scored predictions\n",
    "    L -- number of results to be considered\n",
    "    \n",
    "    return:\n",
    "    List of precisions for each set of results\n",
    "    \"\"\"\n",
    "    results = [sorted(filter(lambda x: x != None, result), key=lambda x: x[2]['score'], reverse=True) for result in results]\n",
    "    edge_set = set(G.edges())\n",
    "    true_positives = [[(edge[0],edge[1]) for edge in result[0:L] if (edge[0], edge[1]) in edge_set] for result in results]\n",
    "    return [1.0*len(trues)/L for trues in true_positives]\n",
    "\n",
    "def AUC(G, results):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    results = [filter(lambda x: x != None, result) for result in results]\n",
    "    edge_set = set(G.edges())\n",
    "    true_edges = []\n",
    "    false_edges = []\n",
    "    AUC = []\n",
    "    for result_set in results:\n",
    "        for (x,y,data) in result_set:\n",
    "            if (x,y) in edge_set:\n",
    "                true_edges.append((x,y,data))\n",
    "            else:\n",
    "                false_edges.append((x,y,data))\n",
    "        \n",
    "        random.shuffle(true_edges)\n",
    "        random.shuffle(false_edges)\n",
    "        n = len(true_edges)\n",
    "        n_better = 0\n",
    "        n_same = 0\n",
    "        for i in range(0, n):\n",
    "            if true_edges[i][2]['score'] > false_edges[i][2]['score']:\n",
    "                n_better += 1\n",
    "            if true_edges[i][2]['score'] == false_edges[i][2]['score']:\n",
    "                n_same += 1\n",
    "        AUC.append(1.0*(n_better + 0.5*n_same)/n)\n",
    "    return AUC\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%time acm_results = k_fold_validate(GCC, 5, average_commute_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10min 13s\n"
     ]
    }
   ],
   "source": [
    "%time lhn2_results = k_fold_validate(GCC, 5, leicht_holme_newman_global, alpha=.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 55.7 s\n"
     ]
    }
   ],
   "source": [
    "%time lp_results = k_fold_validate(GCC, 5, local_path_index, epsilon=0.01, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LP:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'GCC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-cf2a5ff9c542>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"LP:\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGCC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlp_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAUC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGCC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlp_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"ACM:\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGCC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macm_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GCC' is not defined"
     ]
    }
   ],
   "source": [
    "print \"LP:\"\n",
    "print sum(precision(GCC, lp_results, 50))/5\n",
    "print sum(AUC(GCC, lp_results))/5\n",
    "print \"ACM:\"\n",
    "print sum(precision(GCC, acm_results, 50))/5\n",
    "print sum(AUC(GCC, acm_results))/5\n",
    "print \"LHN2:\"\n",
    "print sum(precision(GCC, lhn2_results, 50))/5\n",
    "print sum(AUC(GCC, lhn2_results))/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 30s\n"
     ]
    }
   ],
   "source": [
    "%time katz_results = k_fold_validate(GCC, 5, katz_index, beta=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Katz:\n",
      "0.488\n",
      "0.789415714946\n"
     ]
    }
   ],
   "source": [
    "print \"Katz:\"\n",
    "print sum(precision(GCC, katz_results, 50))/5\n",
    "print sum(AUC(GCC, katz_results))/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cn_results = k_fold_validate(GCC, 5, common_neighbors)\n",
    "jaccard_results = k_fold_validate(GCC, 5, jaccard)\n",
    "salton_results = k_fold_validate(GCC, 5, salton)\n",
    "pa_results = k_fold_validate(GCC, 5, preferential_attachment)\n",
    "hdi_results = k_fold_validate(GCC, 5, hub_depressed)\n",
    "hpi_results = k_fold_validate(GCC, 5, hub_promoted)\n",
    "ra_results = k_fold_validate(GCC, 5, resource_allocation)\n",
    "aa_results = k_fold_validate(GCC, 5, adamic_adar)\n",
    "sorensen_results = k_fold_validate(GCC, 5, sorensen)\n",
    "lhn_results = k_fold_validate(GCC,5, leicht_holme_newman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN:\n",
      "0.56\n",
      "0.732126698625\n",
      "Jaccard:\n",
      "0.676\n",
      "0.731940332014\n",
      "Salton:\n",
      "0.644\n",
      "0.730523032069\n",
      "Preferential Attachment:\n",
      "0.584\n",
      "0.687812447298\n",
      "Hub depressed:\n",
      "0.528\n",
      "0.509619538487\n",
      "Hub promoted:\n",
      "0.524\n",
      "0.502228014661\n",
      "Resource allocation:\n",
      "0.636\n",
      "0.730200885742\n",
      "Adamic/Adar:\n",
      "0.636\n",
      "0.731402418121\n",
      "Sorensen:\n",
      "0.52\n",
      "0.502034300796\n",
      "LHN:\n",
      "0.792\n",
      "0.508301686647\n"
     ]
    }
   ],
   "source": [
    "print \"CN:\"\n",
    "print sum(precision(GCC, cn_results, 50))/5\n",
    "print sum(AUC(GCC, cn_results))/5\n",
    "print \"Jaccard:\"\n",
    "print sum(precision(GCC, jaccard_results, 50))/5\n",
    "print sum(AUC(GCC, jaccard_results))/5\n",
    "print \"Salton:\"\n",
    "print sum(precision(GCC, salton_results, 50))/5\n",
    "print sum(AUC(GCC, salton_results))/5\n",
    "print \"Preferential Attachment:\"\n",
    "print sum(precision(GCC, pa_results, 50))/5\n",
    "print sum(AUC(GCC, pa_results))/5\n",
    "print \"Hub depressed:\"\n",
    "print sum(precision(GCC, hdi_results, 50))/5\n",
    "print sum(AUC(GCC, hdi_results))/5\n",
    "print \"Hub promoted:\"\n",
    "print sum(precision(GCC, hpi_results, 50))/5\n",
    "print sum(AUC(GCC, hpi_results))/5\n",
    "print \"Resource allocation:\"\n",
    "print sum(precision(GCC, ra_results, 50))/5\n",
    "print sum(AUC(GCC, ra_results))/5\n",
    "print \"Adamic/Adar:\"\n",
    "print sum(precision(GCC, aa_results, 50))/5\n",
    "print sum(AUC(GCC, aa_results))/5\n",
    "print \"Sorensen:\"\n",
    "print sum(precision(GCC, sorensen_results, 50))/5\n",
    "print sum(AUC(GCC, sorensen_results))/5\n",
    "print \"LHN:\"\n",
    "print sum(precision(GCC, lhn_results, 50))/5\n",
    "print sum(AUC(GCC, lhn_results))/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
