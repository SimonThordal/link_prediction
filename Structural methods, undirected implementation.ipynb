{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run load_data.py\n",
    "import sys\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import scipy.sparse.linalg as splin\n",
    "import scipy.sparse as sparse\n",
    "import random\n",
    "import math\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this document the methods described in the methods section are implemented for the network of verdicts. The data is loaded as `networkx`directed graph making it relatively easy to work with. The goal is to set up an easily used interface for running K-folds cross validation on the network for different link prediction algorithms and evaluate them with ROC and precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the greatest connected component and work on that\n",
    "components = []\n",
    "lengths = []\n",
    "# Find the greatest component from the undirected version of the graph\n",
    "for component in nx.connected_component_subgraphs(nx.Graph(G)):\n",
    "    components.append(component)\n",
    "    lengths.append(len(component))\n",
    "# Find the GCC as the largest component and then recreate the directed graph\n",
    "GCC = components[lengths.index(max(lengths))]\n",
    "GCC = G.subgraph(GCC.nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is an undirected implementation we'll need an undirected version of the GCC. Changing to undirected has a tendency to swap edge the position nodes on edges. Position is necessary to trim the graph, so we'll make sure that `edge[0]` is always younger than `edge[1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an undirected copy of the GCC and make sure that the edges in the copy respect causality\n",
    "GCC_un = nx.Graph(GCC.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scope_to_node(nodes, head_node, G):\n",
    "    \"\"\"\n",
    "    Filter a set of nodes to the timestamp specified on head_node\n",
    "    \n",
    "    arguments:\n",
    "    nodes -- list of nodes to be filtered\n",
    "    head_node -- node containing the timestamp to filter the nodes by\n",
    "    \"\"\"\n",
    "    max_date = G.node[head_node]['date']\n",
    "    return [n for n in nodes if G.node[n]['date'] <= max_date]\n",
    "\n",
    "def scoped_neighborhood(node, head_node, G):\n",
    "    \"\"\"\n",
    "    Return the neighborhood of a node at a given timestamp\n",
    "    \n",
    "    arguments:\n",
    "    node -- node to find the neighborhood for\n",
    "    head_node -- node containing the timestamp to filter the nodes by\n",
    "    \"\"\"\n",
    "    max_date = G.node[head_node]['date']\n",
    "    neighborhood = [n for n in G.neighbors(node) if G.node[n]['date'] <= max_date]\n",
    "    return neighborhood    \n",
    "    \n",
    "def scoped_degree(node, head_node, G):\n",
    "    \"\"\"\n",
    "    Return the degree of a node at a given timestamp\n",
    "    \n",
    "    arguments:\n",
    "    node -- node to return the degree for\n",
    "    head_node -- node containing the timestamp to filter the nodes by\n",
    "    G -- graph containing the nodes\n",
    "    \"\"\"\n",
    "    max_date = G.node[head_node]['date']\n",
    "    neighborhood = [n for n in G.neighbors(node) if G.node[n]['date'] <= max_date]\n",
    "    return len(neighborhood)\n",
    " \n",
    "def jaccard(validation_set, G):\n",
    "    \"\"\"\n",
    "    Perform Jaccard scoring on a single edge\n",
    "    \n",
    "    arguments:\n",
    "    non_edge -- edge tuple specified by node endpoints\n",
    "    G -- graph containing the nodes in the edge\n",
    "    \n",
    "    return:\n",
    "    edges with the score as an attribute\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        u = set(scoped_neighborhood(non_edge[0], non_edge[0], G))\n",
    "        v = set(scoped_neighborhood(non_edge[1], non_edge[0], G))\n",
    "        uv_un = 1.0*len(u.union(v))\n",
    "        uv_int = 1.0*len(u.intersection(v))\n",
    "        if uv_int == 0 or uv_un == 0:\n",
    "            s= 0.0\n",
    "        else:\n",
    "            s = uv_int/uv_un\n",
    "        non_edge[2]['score'] = s\n",
    "        results.append(non_edge)\n",
    "    return results\n",
    "    \n",
    "def common_neighbors(validation_set, G):\n",
    "    \"\"\"\n",
    "    Perform common neighbors scoring on a single edge\n",
    "    \n",
    "    arguments:\n",
    "    non_edge -- edge tuple specified by node endpoints\n",
    "    G -- graph containing the nodes in the edge\n",
    "    \n",
    "    return:\n",
    "    edges with the score as an attribute\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        u = set(scoped_neighborhood(non_edge[0], non_edge[0], G))\n",
    "        v = set(scoped_neighborhood(non_edge[1], non_edge[0], G))\n",
    "        s = len(u.intersection(v))\n",
    "        non_edge[2]['score'] = s\n",
    "        results.append(non_edge)\n",
    "    return results\n",
    "\n",
    "def adamic_adar(validation_set, G):\n",
    "    \"\"\"\n",
    "    Perform Adamic/Adar scoring on a single edge\n",
    "    \n",
    "    arguments:\n",
    "    non_edge -- edge tuple specified by node endpoints\n",
    "    G -- graph containing the nodes in the edge\n",
    "    \n",
    "    return:\n",
    "    edges with the score as an attribute\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        u = set(scoped_neighborhood(non_edge[0], non_edge[0], G))\n",
    "        v = set(scoped_neighborhood(non_edge[1], non_edge[0], G))\n",
    "        uv_int = u.intersection(v)\n",
    "        s = sum([1.0/math.log(scoped_degree(node, node, G)) for node in uv_int if scoped_degree(node, node, G) != 1 and scoped_degree(node, node, G) != 0])\n",
    "        if s == None:\n",
    "            s = 0.0\n",
    "        non_edge[2]['score'] = s\n",
    "        results.append(non_edge)\n",
    "    return results\n",
    "\n",
    "def resource_allocation(validation_set, G):\n",
    "    \"\"\"\n",
    "    Perform resource allocation scoring on a single edge\n",
    "    \n",
    "    arguments:\n",
    "    non_edge -- edge tuple specified by node endpoints\n",
    "    G -- graph containing the nodes in the edge\n",
    "    \n",
    "    return:\n",
    "    edges with the score as an attribute\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        u = set(scoped_neighborhood(non_edge[0], non_edge[0], G))\n",
    "        v = set(scoped_neighborhood(non_edge[1], non_edge[0], G))\n",
    "        uv_int = u.intersection(v)\n",
    "        s = sum([1.0/scoped_degree(node, node, G) for node in uv_int if scoped_degree(node, node, G) != 0])\n",
    "        non_edge[2]['score'] = s\n",
    "        results.append(non_edge)\n",
    "    return results\n",
    "\n",
    "def leicht_holme_newman(validation_set, G):\n",
    "    \"\"\"\n",
    "    Perform LHN1 scoring on a single edge\n",
    "    \n",
    "    arguments:\n",
    "    non_edge -- edge tuple specified by node endpoints\n",
    "    G -- graph containing the nodes in the edge\n",
    "    \n",
    "    return:\n",
    "    edges with the score as an attribute\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        u = set(scoped_neighborhood(non_edge[0], non_edge[0], G))\n",
    "        v = set(scoped_neighborhood(non_edge[1], non_edge[0], G))\n",
    "        uv_int = 1.0*len(u.intersection(v))\n",
    "        if scoped_degree(non_edge[0], non_edge[0], G) == 0 or scoped_degree(non_edge[1], non_edge[0], G) == 0:\n",
    "            s = 0.0\n",
    "        else:\n",
    "            s = uv_int/(scoped_degree(non_edge[0], non_edge[0], G)*scoped_degree(non_edge[1], non_edge[0], G))\n",
    "        non_edge[2]['score'] = s\n",
    "        results.append(non_edge)\n",
    "    return results\n",
    "\n",
    "def sorensen(validation_set, G):\n",
    "    \"\"\"\n",
    "    Perform SÃ¸rensen index scoring on a single edge\n",
    "    \n",
    "    arguments:\n",
    "    non_edge -- edge tuple specified by node endpoints\n",
    "    G -- graph containing the nodes in the edge\n",
    "    \n",
    "    return:\n",
    "    edges with the score as an attribute\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        u = set(scoped_neighborhood(non_edge[0], non_edge[0], G))\n",
    "        v = set(scoped_neighborhood(non_edge[1], non_edge[0], G))\n",
    "        uv_int = 1.0*len(u.intersection(v))\n",
    "        if scoped_degree(non_edge[0], non_edge[0], G) == 0 and scoped_degree(non_edge[1], non_edge[0], G) == 0:\n",
    "            s = 0.0\n",
    "        else:\n",
    "            s = 2.0*uv_int/(scoped_degree(non_edge[0], non_edge[0], G)+scoped_degree(non_edge[1], non_edge[0], G))\n",
    "        non_edge[2]['score'] = s\n",
    "        results.append(non_edge)\n",
    "    return results\n",
    "\n",
    "def hub_promoted(validation_set, G):\n",
    "    \"\"\"\n",
    "    Perform hub promoted index scoring on a single edge\n",
    "    \n",
    "    arguments:\n",
    "    non_edge -- edge tuple specified by node endpoints\n",
    "    G -- graph containing the nodes in the edge\n",
    "    \n",
    "    return:\n",
    "    edges with the score as an attribute\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        u = set(scoped_neighborhood(non_edge[0], non_edge[0], G))\n",
    "        v = set(scoped_neighborhood(non_edge[1], non_edge[0], G))\n",
    "        uv_int = 1.0*len(u.intersection(v))\n",
    "        if scoped_degree(non_edge[0], non_edge[0], G) == 0 and scoped_degree(non_edge[1], non_edge[0], G) == 0:\n",
    "            s = 0.0\n",
    "        else:\n",
    "            s = uv_int/max(scoped_degree(non_edge[0], non_edge[0], G), scoped_degree(non_edge[1], non_edge[0], G))\n",
    "        non_edge[2]['score'] = s\n",
    "        results.append(non_edge)\n",
    "    return results\n",
    "\n",
    "def hub_depressed(validation_set, G):\n",
    "    \"\"\"\n",
    "    Perform hub promoted index scoring on a single edge\n",
    "    \n",
    "    arguments:\n",
    "    non_edge -- edge tuple specified by node endpoints\n",
    "    G -- graph containing the nodes in the edge\n",
    "    \n",
    "    return:\n",
    "    edges with the score as an attribute\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        u = set(scoped_neighborhood(non_edge[0], non_edge[0], G))\n",
    "        v = set(scoped_neighborhood(non_edge[1], non_edge[0], G))\n",
    "        uv_int = 1.0*len(u.intersection(v))\n",
    "        if scoped_degree(non_edge[0], non_edge[0], G) == 0 or scoped_degree(non_edge[1], non_edge[0], G) == 0:\n",
    "            s = 0.0\n",
    "        else:\n",
    "            s = uv_int/min(scoped_degree(non_edge[0], non_edge[0], G), scoped_degree(non_edge[1], non_edge[0], G))\n",
    "        non_edge[2]['score'] = s\n",
    "        results.append(non_edge)\n",
    "    return results\n",
    "\n",
    "def salton(validation_set, G):\n",
    "    \"\"\"\n",
    "    Perform Salton index scoring on a single edge\n",
    "    \n",
    "    arguments:\n",
    "    non_edge -- edge tuple specified by node endpoints\n",
    "    G -- graph containing the nodes in the edge\n",
    "    \n",
    "    return:\n",
    "    edges with the score as an attribute\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        u = set(scoped_neighborhood(non_edge[0], non_edge[0], G))\n",
    "        v = set(scoped_neighborhood(non_edge[1], non_edge[0], G))\n",
    "        uv_int = 1.0*len(u.intersection(v))\n",
    "        if scoped_degree(non_edge[0], non_edge[0], G) == 0 or scoped_degree(non_edge[1], non_edge[0], G) == 0:\n",
    "            s = 0.0\n",
    "        else:\n",
    "            s = uv_int/math.sqrt(scoped_degree(non_edge[0], non_edge[0], G)*scoped_degree(non_edge[1], non_edge[0], G))\n",
    "        non_edge[2]['score'] = s\n",
    "        results.append(non_edge)\n",
    "    return results\n",
    "\n",
    "def preferential_attachment(validation_set, G):\n",
    "    \"\"\"\n",
    "    Perform preferential attachment scoring on a single edge\n",
    "    \n",
    "    arguments:\n",
    "    non_edge -- edge tuple specified by node endpoints\n",
    "    G -- graph containing the nodes in the edge\n",
    "    \n",
    "    return:\n",
    "    edges with the score as an attribute\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        s = scoped_degree(non_edge[0], non_edge[0], G)*scoped_degree(non_edge[1], non_edge[0], G)\n",
    "        non_edge[2]['score'] = s\n",
    "        results.append(non_edge)\n",
    "    return results\n",
    "\n",
    "## Global index similarities, computed based on every path between two nodes. SLower than local indices but contain full\n",
    "## information\n",
    "def katz_index(validation_set, G, beta):\n",
    "    \"\"\"\n",
    "    Return a weighted sum over every path between two nodes, s_xy = sum(beta*A+beta^2*A^2+...) = (I-beta*A^(-1))-I\n",
    "    \n",
    "    arguments:\n",
    "    validation_set -- set of edges between nodes to be considered\n",
    "    A_inv -- Precomputed inverse of the adjacency matrix\n",
    "    beta -- weighting parameter, the smaller it is the closer the result is to CN\n",
    "    \n",
    "    return:\n",
    "    list of edges with the score as an attribute\n",
    "    \"\"\"\n",
    "    A = nx.adjacency_matrix(G)\n",
    "    # Create indices to access A\n",
    "    id_to_ind = {node: i for (i, node) in zip(range(0, len(G.nodes())), G.nodes())}\n",
    "    max_eig = splin.eigsh(A.asfptype(), k=1, which='LM', return_eigenvectors=False)[0]\n",
    "    if 1.0/max_eig <= beta:\n",
    "        raise Exception(\"Beta must be less than or equal to the maximum eigenvalue of A(G), which is: {}\".format(1.0/max_eig))\n",
    "    \n",
    "    I = np.identity(A.shape[0])\n",
    "    S = np.linalg.inv(I-beta*A.todense()) - I\n",
    "    results = [(x,y, {'score': S[id_to_ind[x], id_to_ind[y]]}) for (x,y) in validation_set]\n",
    "    return results\n",
    "\n",
    "def leicht_holme_newman_global(validation_set, G, alpha):\n",
    "    \"\"\"\n",
    "    Return a weighted sum of every path between two nodes, s_xy = sum(I+omega*A+omega^2*A^2+...)\n",
    "    \"\"\"\n",
    "    A = nx.adjacency_matrix(G)\n",
    "    # Create indices to access A\n",
    "    id_to_ind = {node: i for (i, node) in zip(range(0, len(G.nodes())), G.nodes())}\n",
    "    M = len(G.edges())\n",
    "    max_eig = splin.eigsh(A.asfptype(), k=1, which='LM', return_eigenvectors=False)[0]\n",
    "    I = np.identity(A.shape[0])\n",
    "    D_inv = np.linalg.inv(I+np.diag(G.degree().values())) # TODO: This normally does not have the I factor, but this is done to remove 0-rows creating singular matrices\n",
    "    A_inv=np.linalg.inv((I-alpha*A)/max_eig)\n",
    "    S = 2*M*max_eig*D_inv*A_inv*D_inv\n",
    "    results = [(x,y, {'score': S[id_to_ind[x], id_to_ind[y]]}) for (x,y) in validation_set]\n",
    "    return results\n",
    "\n",
    "def average_commute_time(validation_set, G):\n",
    "    \"\"\"\n",
    "    Return the score as the inverse of the average commute time between two nodes, found as the pseudo inverse of the Laplacian\n",
    "    \"\"\"\n",
    "    A = nx.adjacency_matrix(G)\n",
    "    # Create indices to access A\n",
    "    id_to_ind = {node: i for (i, node) in zip(range(0, len(G.nodes())), G.nodes())}\n",
    "    L_plus = np.linalg.pinv(nx.laplacian_matrix(G).todense())\n",
    "    results = []\n",
    "    scoring = lambda x,y: 1.0/(L_plus[id_to_ind[x], id_to_ind[x]] + L_plus[id_to_ind[y], id_to_ind[y]] - 2*L_plus[id_to_ind[x], id_to_ind[y]])\n",
    "    for x,y in validation_set:\n",
    "        results.append((x,y, {'score': scoring(x,y)}))\n",
    "    return results\n",
    "\n",
    "def local_path_index(validation_set, G, epsilon, n):\n",
    "    \"\"\"\n",
    "    The same as the katz index, but constricted to paths of length n\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for x,y in validation_set:\n",
    "        count = [0 for _ in range(0, n+1)]\n",
    "        q = [(x, 0)]\n",
    "        while len(q) != 0:\n",
    "            v, dist = q.pop()\n",
    "            for w in G.neighbors(v):\n",
    "                if dist < (n-1):\n",
    "                    q.append((w, dist + 1))\n",
    "                if dist < n and w == y:\n",
    "                    count[dist] += 1\n",
    "        s = sum([math.pow(epsilon,1.0*i)*c for i, c in zip(range(0, len(count) + 1), count)])\n",
    "        results.append((x,y, {'score': s}))\n",
    "    return results\n",
    "\n",
    "def local_random_walk(validation_set, G, t):\n",
    "    \"\"\"\n",
    "    \n",
    "    arguments:\n",
    "    validation_set -- set of edges between nodes to be considered\n",
    "    G -- the graph the validation set is evaluated against\n",
    "    n -- number of steps to be considered\n",
    "    \n",
    "    return:\n",
    "    list of edges with the score as an attribute\n",
    "    \"\"\"\n",
    "    for x,y in validation_set:\n",
    "        pi_xy = 0\n",
    "        pi_yx = 0\n",
    "        for tau in range(1, t+1):\n",
    "            d_x = 0\n",
    "                \n",
    "def valid_random_non_edges(graph, n):\n",
    "    \"\"\"\n",
    "    Returns randomized, non-existent links between nodes in the graph that are guaranteed to observe causality.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : NetworkX graph.\n",
    "        Graph to find non-existent edges.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    non_edges : iterator\n",
    "        Iterator of edges that are not in the graph.\n",
    "    \"\"\"\n",
    "    result_pairs = []\n",
    "    # Sort edges according to age\n",
    "    sorted_edges =[node for node, data in sorted(graph.nodes(data=True), key=lambda x: x[1]['date'], reverse=True)]\n",
    "    node_set = set(graph.nodes())\n",
    "    candidates = list(np.random.choice(sorted_edges, n, replace=True))\n",
    "    i = 0\n",
    "    while i < len(candidates):\n",
    "        u = candidates[i]\n",
    "        # Make sure the potential neighbors respect causality with a resolution equal to the timestamp\n",
    "        cand_index = sorted_edges.index(u)\n",
    "        potential_neighbors = set(sorted_edges[cand_index:])\n",
    "        if graph.is_directed():\n",
    "            neighbors = set(graph.successors(u)).union(set(graph.predecessors(u)))\n",
    "        else:\n",
    "            neighbors = set(graph.neighbors(u))\n",
    "        # Make sure the potential neighbors respect causality\n",
    "        non_neighbors = list(potential_neighbors - neighbors)\n",
    "        # The oldest node will have a neighborhood of Ã, so add a new candidate to the list in that case\n",
    "        if len(non_neighbors) == 0:\n",
    "            candidates.append(random.choice(graph.nodes()))\n",
    "        else:    \n",
    "            result_pairs.append((u, random.choice(non_neighbors)))\n",
    "        i += 1\n",
    "    return result_pairs\n",
    "        \n",
    "\n",
    "def k_fold_validate(G, k, fun, **kwargs):\n",
    "    \"\"\"\n",
    "    K-fold validation of some specified function\n",
    "    \n",
    "    arguments:\n",
    "    G -- Graph to perform the function on\n",
    "    k -- number of folds\n",
    "    fun -- function to be evaluated\n",
    "    kwargs -- arguments to be passed to the evaluated function\n",
    "    \n",
    "    return:\n",
    "    List of lists of scored predictions\n",
    "    \"\"\"\n",
    "    # Use an undirected graph for now\n",
    "    G_undirected = nx.Graph(G.copy())\n",
    "    edges = G_undirected.edges(data=True)\n",
    "    \n",
    "    random.shuffle(edges)\n",
    "    # Find the number of true members in the validation set\n",
    "    N = len(edges)/k\n",
    "    validation_sets = []\n",
    "    for i in range(0,k):\n",
    "        validation_sets.append(edges[i*N:(i+1)*N])\n",
    "    results = []\n",
    "    for true_validation_set in validation_sets:\n",
    "        # Create a training set and remove all true members of the validation set from it\n",
    "        G_train = G_undirected.copy()\n",
    "        G_train.remove_edges_from(true_validation_set)\n",
    "        \n",
    "        # Fetch random edges guaranteed not to be in the graph\n",
    "        false_validation_set = valid_random_non_edges(G_undirected, len(true_validation_set))\n",
    "        # Trim out and replace edges if they break causality. Continue doing this until the set is the size of the validation set\n",
    "        for i in range(len(false_validation_set)):\n",
    "            edge = false_validation_set[i]\n",
    "            # Add date information to the non-edge\n",
    "            false_validation_set[i] = edge + ({'date': G.node[edge[0]]['date']},)\n",
    "        \n",
    "        # Make sure the true edges have sane orientation since this can be flipped when creating an undirected graph\n",
    "        for i in range(len(true_validation_set)):\n",
    "            edge = true_validation_set[i]\n",
    "            if G.node[edge[0]]['date'] < G.node[edge[1]]['date']:\n",
    "                true_validation_set[i] = (edge[1], edge[0], edge[2])\n",
    "        \n",
    "        validation_set = true_validation_set + false_validation_set\n",
    "        # If not shuffled, subsequent sorting algorithms will always rank true edges higher than false edges when they have\n",
    "        # the same score\n",
    "        random.shuffle(validation_set)\n",
    "        results.append(fun(validation_set, G_train, **kwargs))\n",
    "    return results\n",
    "\n",
    "def precision(G, results, L):\n",
    "    \"\"\"\n",
    "    Find the ratio of the true positives to trues\n",
    "    \n",
    "    arguments:\n",
    "    G -- graph the results are based on\n",
    "    results -- list of lists of scored predictions\n",
    "    L -- number of results to be considered\n",
    "    \n",
    "    return:\n",
    "    List of precisions for each set of results\n",
    "    \"\"\"\n",
    "    # Sort the results with descending scores\n",
    "    results = [sorted(result, key=lambda x: x[2]['score'], reverse=True) for result in results]\n",
    "    edge_set = set(G.edges())\n",
    "    # True positives exist in both the edge set and the result set\n",
    "    true_positives = [[(edge[0],edge[1]) for edge in result[0:L] if (edge[0], edge[1]) in edge_set] for result in results]\n",
    "    return [1.0*len(trues)/L for trues in true_positives]\n",
    "\n",
    "def AUC(G, results):\n",
    "    \"\"\"\n",
    "    Perform n trials where the score of a non-edge and an edge in the result is compared. Count the number of trials where\n",
    "    the edge had the higher score as n' and the number of times the score was equal as n'' and return the AUC as (n' + n'')/n.\n",
    "    \n",
    "    arguments:\n",
    "    G -- graph the results are based on\n",
    "    results -- list of lists of scored predictions\n",
    "    \n",
    "    return:\n",
    "    List of precisions for each set of results\n",
    "    \"\"\"\n",
    "    \n",
    "    edge_set = set(G.edges())\n",
    "    AUC = []\n",
    "    for result_set in results:\n",
    "        true_edges = []\n",
    "        false_edges = []\n",
    "        for (x,y,data) in result_set:\n",
    "            if (x,y) in edge_set:\n",
    "                true_edges.append((x,y,data))\n",
    "            else:\n",
    "                false_edges.append((x,y,data))\n",
    "        \n",
    "        random.shuffle(true_edges)\n",
    "        random.shuffle(false_edges)\n",
    "        n = len(true_edges)\n",
    "        n_better = 0.0\n",
    "        n_same = 0.0\n",
    "        for i in range(0, n):\n",
    "            if true_edges[i][2]['score'] > false_edges[i][2]['score']:\n",
    "                n_better += 1.0\n",
    "            if true_edges[i][2]['score'] == false_edges[i][2]['score']:\n",
    "                n_same += 1.0\n",
    "        AUC.append((n_better + 0.5*n_same)/n)\n",
    "    return AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time acm_results = k_fold_validate(GCC, 5, average_commute_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time lhn2_results = k_fold_validate(GCC, 5, leicht_holme_newman_global, alpha=.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time lp_results = k_fold_validate(GCC, 5, local_path_index, epsilon=0.01, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"LP:\"\n",
    "print sum(precision(GCC, lp_results, 50))/5\n",
    "print sum(AUC(GCC, lp_results))/5\n",
    "print \"ACM:\"\n",
    "print sum(precision(GCC, acm_results, 50))/5\n",
    "print sum(AUC(GCC, acm_results))/5\n",
    "print \"LHN2:\"\n",
    "print sum(precision(GCC, lhn2_results, 50))/5\n",
    "print sum(AUC(GCC, lhn2_results))/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time katz_results = k_fold_validate(GCC, 5, katz_index, beta=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Katz:\"\n",
    "print sum(precision(GCC, katz_results, 50))/5\n",
    "print sum(AUC(GCC, katz_results))/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'6'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-8958e26519d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mhdi_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk_fold_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGCC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhub_depressed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mhpi_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk_fold_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGCC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhub_promoted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mra_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk_fold_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGCC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresource_allocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0maa_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk_fold_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGCC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madamic_adar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0msorensen_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk_fold_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGCC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorensen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-e3f0cf2c5200>\u001b[0m in \u001b[0;36mk_fold_validate\u001b[1;34m(G, k, fun, **kwargs)\u001b[0m\n\u001b[0;32m    441\u001b[0m         \u001b[1;31m# the same score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-e3f0cf2c5200>\u001b[0m in \u001b[0;36mresource_allocation\u001b[1;34m(validation_set, G)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoped_neighborhood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnon_edge\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_edge\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0muv_int\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mscoped_degree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0muv_int\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mscoped_degree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[0mnon_edge\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnon_edge\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-e3f0cf2c5200>\u001b[0m in \u001b[0;36mscoped_degree\u001b[1;34m(node, head_node, G)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mG\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \"\"\"\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mmax_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhead_node\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0mneighborhood\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mmax_date\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneighborhood\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '6'"
     ]
    }
   ],
   "source": [
    "cn_results = k_fold_validate(GCC, 5, common_neighbors)\n",
    "jaccard_results = k_fold_validate(GCC, 5, jaccard)\n",
    "salton_results = k_fold_validate(GCC, 5, salton)\n",
    "pa_results = k_fold_validate(GCC, 5, preferential_attachment)\n",
    "hdi_results = k_fold_validate(GCC, 5, hub_depressed)\n",
    "hpi_results = k_fold_validate(GCC, 5, hub_promoted)\n",
    "ra_results = k_fold_validate(GCC, 5, resource_allocation)\n",
    "aa_results = k_fold_validate(GCC, 5, adamic_adar)\n",
    "sorensen_results = k_fold_validate(GCC, 5, sorensen)\n",
    "lhn_results = k_fold_validate(GCC,5, leicht_holme_newman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ra_results = k_fold_validate(GCC, 5, resource_allocation)\n",
    "aa_results = k_fold_validate(GCC, 5, adamic_adar)\n",
    "sorensen_results = k_fold_validate(GCC, 5, sorensen)\n",
    "lhn_results = k_fold_validate(GCC,5, leicht_holme_newman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN:\n",
      "0.98\n",
      "0.793499877808\n",
      "Jaccard:\n",
      "0.872\n",
      "0.791675081957\n",
      "Salton:\n",
      "0.848\n",
      "0.792879760169\n",
      "Preferential Attachment:\n",
      "0.988\n",
      "0.779581629685\n",
      "Hub depressed:\n",
      "0.964\n",
      "0.792432684371\n",
      "Hub promoted:\n",
      "0.88\n",
      "0.791778601542\n",
      "Resource allocation:\n",
      "0.984\n",
      "0.780294331651\n",
      "Adamic/Adar:\n",
      "0.996\n",
      "0.764725908114\n",
      "Sorensen:\n",
      "0.852\n",
      "0.792468044325\n",
      "LHN:\n",
      "0.904\n",
      "0.790012132312\n"
     ]
    }
   ],
   "source": [
    "print \"CN:\"\n",
    "print sum(precision(GCC, cn_results, 50))/5\n",
    "print sum(AUC(GCC, cn_results))/5\n",
    "print \"Jaccard:\"\n",
    "print sum(precision(GCC, jaccard_results, 50))/5\n",
    "print sum(AUC(GCC, jaccard_results))/5\n",
    "print \"Salton:\"\n",
    "print sum(precision(GCC, salton_results, 50))/5\n",
    "print sum(AUC(GCC, salton_results))/5\n",
    "print \"Preferential Attachment:\"\n",
    "print sum(precision(GCC, pa_results, 50))/5\n",
    "print sum(AUC(GCC, pa_results))/5\n",
    "print \"Hub depressed:\"\n",
    "print sum(precision(GCC, hdi_results, 50))/5\n",
    "print sum(AUC(GCC, hdi_results))/5\n",
    "print \"Hub promoted:\"\n",
    "print sum(precision(GCC, hpi_results, 50))/5\n",
    "print sum(AUC(GCC, hpi_results))/5\n",
    "print \"Resource allocation:\"\n",
    "print sum(precision(GCC, ra_results, 50))/5\n",
    "print sum(AUC(GCC, ra_results))/5\n",
    "print \"Adamic/Adar:\"\n",
    "print sum(precision(GCC, aa_results, 50))/5\n",
    "print sum(AUC(GCC, aa_results))/5\n",
    "print \"Sorensen:\"\n",
    "print sum(precision(GCC, sorensen_results, 50))/5\n",
    "print sum(AUC(GCC, sorensen_results))/5\n",
    "print \"LHN:\"\n",
    "print sum(precision(GCC, lhn_results, 50))/5\n",
    "print sum(AUC(GCC, lhn_results))/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 46.1 s\n"
     ]
    }
   ],
   "source": [
    "%time cn_results = k_fold_validate(GCC, 5, common_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17466"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aa_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN:\n",
      "0.978666666667\n",
      "0.792708029249\n"
     ]
    }
   ],
   "source": [
    "print \"CN:\"\n",
    "print sum(precision(GCC, cn_results, 150))/5\n",
    "print sum(AUC(GCC, cn_results))/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN:\n",
      "0.989333333333\n",
      "0.792214809053\n"
     ]
    }
   ],
   "source": [
    "print \"CN:\"\n",
    "print sum(precision(GCC, cn_results, 150))/5\n",
    "print sum(AUC(GCC, cn_results))/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 47.9 s\n"
     ]
    }
   ],
   "source": [
    "%time pa_results = k_fold_validate(GCC, 5, preferential_attachment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preferential Attachment:\n",
      "0.978666666667\n",
      "0.779398878645\n"
     ]
    }
   ],
   "source": [
    "print \"Preferential Attachment:\"\n",
    "print sum(precision(GCC, pa_results, 150))/5\n",
    "print sum(AUC(GCC, pa_results))/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preferential Attachment:\n",
      "0.977333333333\n",
      "0.795289473358\n"
     ]
    }
   ],
   "source": [
    "print \"Preferential Attachment:\"\n",
    "print sum(precision(GCC, pa_results, 150))/5\n",
    "print sum(AUC(GCC, pa_results))/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = Counter([node[1]['date'] for node in GCC.nodes(data=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = 0\n",
    "for node in GCC_un.nodes():\n",
    "    for n in GCC_un.neighbors(node):\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87247\n"
     ]
    }
   ],
   "source": [
    "print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43694"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
