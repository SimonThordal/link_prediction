{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import scipy.sparse.linalg as splin\n",
    "import random\n",
    "import math\n",
    "import heapq\n",
    "from os.path import isfile\n",
    "from sklearn.externals.six import StringIO\n",
    "import pydotplus\n",
    "import igraph as ig\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score, make_scorer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import RFECV, SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from collections import *\n",
    "import cPickle as pkl\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, SVR\n",
    "from scipy.sparse import dok_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "# Database nonsense\n",
    "# Intitalize the collection \n",
    "def set_up_collection(name):\n",
    "    \"\"\"\n",
    "    Set up a collection of edges for a named graph\n",
    "    This will ensure that the fields edge, source and target exists, that edges are unique and there's an index on source\n",
    "    \"\"\"\n",
    "    client = pymongo.MongoClient()\n",
    "    db = client[name]\n",
    "    db['edges'].create_index('edge', unique=True)\n",
    "    db['edges'].create_index('source')\n",
    "    return db['edges']\n",
    "\n",
    "def get_precalculated(candidate_edges, field):\n",
    "    # Find all edges that have the requested field and exists in candidate_edges. \n",
    "    # NB: mongodb doesn't know tuples, so edge is a string\n",
    "    results = []\n",
    "    max_requests = 200000\n",
    "    n = len(candidate_edges) / max_requests\n",
    "    for i in xrange(n):\n",
    "        results += list(edge_col.find({'edge': \n",
    "                                       {'$in': [str((x,y)) for x,y,_ in candidate_edges[i*max_requests:(i+1)*max_requests]]}, \n",
    "                                        field: {'$exists': True}}, \n",
    "                                        {'source': True, 'target': True, field: True}))\n",
    "    results += list(edge_col.find({'edge': \n",
    "                                   {'$in': [str((x,y)) for x,y,_ in candidate_edges[(i+1)*max_requests:]]}, \n",
    "                                    field: {'$exists': True}}, \n",
    "                                    {'source': True, 'target': True, field: True}))\n",
    "\n",
    "    print \"Already calculated: {}\".format(len(results))\n",
    "    # Present the data as expected by feature extractors\n",
    "    results = [(record['source'], record['target'], {'score': record[field]}) for record in results]\n",
    "    # Filter out known edges from the candidate set\n",
    "    known_edges = set([(record[0], record[1]) for record in results])\n",
    "    candidate_edges = [edge for edge in candidate_edges if not (edge[0], edge[1]) in known_edges]\n",
    "    # Return the current results, the unknown edges and the known edges to save time when saving\n",
    "    # NB: known_edges can be omitted although it will make for many more inserts later on\n",
    "    return results, candidate_edges, known_edges\n",
    "\n",
    "\n",
    "def save_precalculated(records, field, pre_calculated):\n",
    "    \n",
    "    pre_calculated = set(pre_calculated)\n",
    "    records = {(x,y):{field: data['score']} for x,y,data in records}\n",
    "    to_be_updated = []\n",
    "    update_filter = list(set(records.keys()) - pre_calculated)\n",
    "    # To avoid the BSON filesize limit of 16 MB per document it is necessary to spread out the queries\n",
    "    max_requests = 200000\n",
    "    n = len(update_filter) / max_requests\n",
    "    for i in xrange(n):\n",
    "        to_be_updated +=  list(edge_col.find({'edge': \n",
    "                                              {'$in': [str(edge) for edge in update_filter[i*max_requests:(i+1)*max_requests]]}, \n",
    "                                              field: {'$exists': False}}))\n",
    "    \n",
    "    to_be_updated += list(edge_col.find({'edge': \n",
    "                                          {'$in': [str(edge) for edge in update_filter[(i+1)*max_requests:]]}, \n",
    "                                          field: {'$exists': False}}))\n",
    "    to_be_deleted = []\n",
    "    for existing_record in to_be_updated:\n",
    "        # Unicode returned from mongo needs to be converted to str the tuple will render wrong when converted to string...sorry\n",
    "        edge = (str(existing_record['source']), str(existing_record['target']))\n",
    "        to_be_deleted.append(str(edge))\n",
    "        records[edge].update(existing_record)\n",
    "    print \"To be updated: {}\".format(len(to_be_deleted))\n",
    "    # Remove all edges that need to be updated\n",
    "    res = edge_col.delete_many({'edge': {'$in': to_be_deleted}})\n",
    "    print \"Deleted: {}:\".format( res.deleted_count)\n",
    "    to_be_saved = []\n",
    "    for edge, data in records.iteritems():\n",
    "        if not edge in pre_calculated:\n",
    "            data.update({'edge' : str(edge), 'source': edge[0], 'target': edge[1]})\n",
    "            to_be_saved.append(data)\n",
    "    print \"To be saved: {}\".format(len(to_be_saved))\n",
    "    if len(to_be_saved) > 0:\n",
    "        edge_col.insert_many(to_be_saved)\n",
    "\n",
    "edge_col = set_up_collection('euchr_test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run load_data.py\n",
    "GRAPH = 'EUCHR'\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "# Find the greatest connected component and work on that\n",
    "components = []\n",
    "lengths = []\n",
    "# Find the greatest component from the undirected version of the graph\n",
    "for component in nx.connected_component_subgraphs(nx.Graph(G)):\n",
    "    components.append(component)\n",
    "    lengths.append(len(component))\n",
    "# Find the GCC as the largest component and then recreate the directed graph\n",
    "GCC = components[lengths.index(max(lengths))]\n",
    "GCC = G.subgraph(GCC.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def successors_scoped(node, head, G):\n",
    "    \"\"\"\n",
    "    Return the successors of a node scoped to the time specified by the head node\n",
    "    \n",
    "    arguments:\n",
    "    node -- node to return successors for\n",
    "    head -- node containing the timestamp to scope the graph to\n",
    "    G -- graph containing the nodes\n",
    "    \"\"\"\n",
    "    max_time = G.node[head]['date']\n",
    "    return [n for n in G[node] if G.node[n]['date'] <= max_time]\n",
    "\n",
    "def predecessors_scoped(node, head, G):\n",
    "    \"\"\"\n",
    "    Return the predecessors of a node scoped to the time specified by the head node\n",
    "    \n",
    "    arguments:\n",
    "    node -- node to return predecessors for\n",
    "    head -- node containing the timestamp to scope the graph to\n",
    "    G -- graph containing the nodes\n",
    "    \"\"\"\n",
    "    max_time = G.node[head]['date']\n",
    "    return [n for n in G.pred[node] if G.node[n]['date'] <= max_time]\n",
    "\n",
    "def scoped_neighborhood(node, head_node, G):\n",
    "    \"\"\"\n",
    "    Return the neighborhood of a node at a given timestamp\n",
    "    \n",
    "    arguments:\n",
    "    node -- node to find the neighborhood for\n",
    "    head_node -- node containing the timestamp to filter the nodes by\n",
    "    G -- directed graph containing the node\n",
    "    \"\"\"\n",
    "    max_date = G.node[head_node]['date']\n",
    "    pre = predecessors_scoped(node, head_node, G)\n",
    "    suc = successors_scoped(node, head_node, G)\n",
    "    return list(set(pre).union(set(suc)))    \n",
    "    \n",
    "def scoped_out_degree(node, head_node, G):\n",
    "    \"\"\"\n",
    "    Return the degree of a node at a given timestamp\n",
    "    \n",
    "    arguments:\n",
    "    node -- node to return the degree for\n",
    "    head_node -- node containing the timestamp to filter the nodes by\n",
    "    G -- graph containing the nodes\n",
    "    \"\"\"\n",
    "    max_date = G.node[head_node]['date']\n",
    "    neighborhood = [n for n in G[node] if G.node[n]['date'] <= max_date]\n",
    "    return len(neighborhood)\n",
    "\n",
    "def scoped_in_degree(node, head_node, G):\n",
    "    \"\"\"\n",
    "    Return the degree of a node at a given timestamp\n",
    "    \n",
    "    arguments:\n",
    "    node -- node to return the degree for\n",
    "    head_node -- node containing the timestamp to filter the nodes by\n",
    "    G -- graph containing the nodes\n",
    "    \"\"\"\n",
    "    max_date = G.node[head_node]['date']\n",
    "    neighborhood = [n for n in G.pred[node] if G.node[n]['date'] <= max_date]\n",
    "    return len(neighborhood)\n",
    "\n",
    "def scoped_degree(node, head_node, G):\n",
    "    \"\"\"\n",
    "    Return the degree of a node at a given timestamop\n",
    "    \"\"\"\n",
    "    return len(scoped_neighborhood(node, head_node, G))\n",
    "\n",
    "def get_common_neighbors(x,y,G):\n",
    "    u = set(scoped_neighborhood(x,x,G))\n",
    "    v = set(scoped_neighborhood(y,x,G))\n",
    "    return u.intersection(v)\n",
    "\n",
    "def get_neighbor_union(x,y,G):\n",
    "    u = set(scoped_neighborhood(x,x,G))\n",
    "    v = set(scoped_neighborhood(y,x,G))\n",
    "    return u.union(v)\n",
    "\n",
    "def get_common_referrers(x,y,G):\n",
    "    common_referrers_source = {n for m in successors_scoped(x, x, G) for n in predecessors_scoped(m, x, G)} - {x}\n",
    "    referrers_to_target = set(predecessors_scoped(y,x,G))\n",
    "    return common_referrers_source.intersection(referrers_to_target)\n",
    "\n",
    "    \n",
    "def common_referrers(validation_set, G, weighting_scheme=None):\n",
    "    \"\"\"\n",
    "    For a given node pair x and y, return the number of nodes that both refer to a node that x also refers and refers to y\n",
    "    or f(y) intersection g(f(x)) where f returns the predeccessors of a node and g returns the successors\n",
    "    \n",
    "    arguments:\n",
    "    validation_set -- list of edges to score\n",
    "    G -- digraph containing the nodes in the edges of the validation set\n",
    "    \n",
    "    returns:\n",
    "    list of edges with score as an attribute\n",
    "    \"\"\"\n",
    " \n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        x = non_edge[0]\n",
    "        y = non_edge[1]\n",
    "        connected = y in G[x]\n",
    "        if connected:\n",
    "            G.remove_edge(x,y)\n",
    "        cn = get_common_referrers(x,y,G)\n",
    "        if weighting_scheme and weighting_scheme.is_local():\n",
    "            weights = []\n",
    "            for z in cn:\n",
    "                weights.append(weighting_scheme.score(z, x, G) * 1.0)\n",
    "            s = sum(weights)\n",
    "        else:\n",
    "            s = len(cn)\n",
    "        if weighting_scheme and weighting_scheme.is_global():\n",
    "            s = s*weighting_scheme.score(x,y,G)\n",
    "        if len(non_edge) > 2:\n",
    "            non_edge[2]['score'] = s\n",
    "            results.append(non_edge)\n",
    "        else:\n",
    "            results.append(s)\n",
    "        if connected:\n",
    "            G.add_edge(x,y)\n",
    "    return results\n",
    "\n",
    "def common_neighbors(validation_set, G, weighting_scheme=None, recalculate=False):\n",
    "    \"\"\"\n",
    "    Perform common neighbors scoring on a list of edges, backed by the database\n",
    "    \n",
    "    arguments:\n",
    "    validation_set -- list of edges to score\n",
    "    G -- digraph containing the nodes in the edges of the validation set\n",
    "    recalculate -- Whether to load edges from the database or recalculate them all    \n",
    "    returns:\n",
    "    list of edges with score as an attribute\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        x = non_edge[0]\n",
    "        y = non_edge[1]\n",
    "        cn = get_common_neighbors(x,y,GCC)\n",
    "        if weighting_scheme and weighting_scheme.is_local():\n",
    "            weights = []\n",
    "            for z in cn:\n",
    "                weights.append(weighting_scheme.score(z, x, GCC) * 1.0)\n",
    "            s = sum(weights)\n",
    "        else:\n",
    "            s = len(cn)\n",
    "        if weighting_scheme and weighting_scheme.is_global():\n",
    "            s = s*weighting_scheme.score(x,y,GCC)\n",
    "        non_edge[2]['score'] = s\n",
    "        results.append(non_edge)\n",
    "    return results\n",
    "\n",
    "class WeightingScheme():\n",
    "    \n",
    "    def is_global(self):\n",
    "        return self.weight_type == \"global\"\n",
    "    def is_local(self):\n",
    "        return self.weight_type == \"local\"\n",
    "        \n",
    "\n",
    "class Jaccard(WeightingScheme):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.weight_type = \"global\"\n",
    "    \n",
    "    def score(self,x,y,G):\n",
    "        \"\"\"\n",
    "        Perform jaccard scoring on a list of edges\n",
    "\n",
    "        arguments:\n",
    "        validation_set -- list of edges to score\n",
    "        G -- digraph containing the nodes in the edges of the validation set\n",
    "\n",
    "        returns:\n",
    "        list of edges with score as an attribute\n",
    "        \"\"\"\n",
    "        u = set(scoped_neighborhood(x,x,G))\n",
    "        v = set(scoped_neighborhood(y,x,G))\n",
    "        try:\n",
    "            s = 1.0*len(u & v)/len(u | v)\n",
    "        except:\n",
    "            s = 0.0\n",
    "        return s\n",
    "    \n",
    "class AdamicAdar(WeightingScheme):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.weight_type = 'local'\n",
    "        \n",
    "    def score(self, z, x, G):\n",
    "        \"\"\"\n",
    "        Return the AdamicAdar coefficient for a single neighbor z, scoped to the time of a node x\n",
    "        \n",
    "        arguments:\n",
    "        z -- node to return the AA coefficient for\n",
    "        x -- node that holds the timestamp to scope z to\n",
    "        G -- graph containing x and z\n",
    "        \"\"\"\n",
    "        deg = scoped_degree(z,x,G)\n",
    "        if deg > 1:\n",
    "            return 1.0/math.log(scoped_degree(z, x, G))\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "        \n",
    "class ResourceAllocation(WeightingScheme):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.weight_type = 'local'\n",
    "        \n",
    "    def score(self, z, x, G):\n",
    "        \"\"\"\n",
    "        Return the RA coefficient for a single neighbor z, scoped to the time of a node x\n",
    "        \n",
    "        arguments:\n",
    "        z -- node to return the AA coefficient for\n",
    "        x -- node that holds the timestamp to scope z to\n",
    "        G -- graph containing x and z\n",
    "        \"\"\"\n",
    "        deg = scoped_degree(z,x,G)\n",
    "        if deg > 1:\n",
    "            return 1.0/scoped_degree(z, x, G)\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "\n",
    "        \n",
    "class LeichtHolmeNewman(WeightingScheme):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.weight_type = 'global'\n",
    "        \n",
    "    def score(self, x, y, G):\n",
    "        \"\"\"\n",
    "        Return the RA coefficient for a single neighbor z, scoped to the time of a node x\n",
    "        \n",
    "        arguments:\n",
    "        z -- node to return the AA coefficient for\n",
    "        x -- node that holds the timestamp to scope z to\n",
    "        G -- graph containing x and z\n",
    "        \"\"\"\n",
    "        x_deg = scoped_degree(x,x,G)\n",
    "        y_deg = scoped_degree(y,x,G)\n",
    "        if x_deg > 0 and y_deg > 0:\n",
    "            return 1.0/x_deg*y_deg\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "class HubDepressed(WeightingScheme):\n",
    "    def __init__(self):\n",
    "        self.weight_type = 'local'\n",
    "\n",
    "    def score(self, x, y, G):\n",
    "        x_deg = scoped_degree(x,x,G)\n",
    "        y_deg = scoped_degree(y,x,G)\n",
    "        if x_deg != 0 and y_deg != 0:\n",
    "            return 1.0/min(x_deg, y_deg)\n",
    "        else:\n",
    "            return 0.0\n",
    "    \n",
    "class HubPromoted(WeightingScheme):\n",
    "    def __init__(self):\n",
    "        self.weight_type = 'global'\n",
    "\n",
    "    def score(self, x, y, G):\n",
    "        x_deg = scoped_degree(x,x,G)\n",
    "        y_deg = scoped_degree(y,x,G)\n",
    "        if x_deg != 0 or y_deg != 0:\n",
    "            return 1.0/max(x_deg, y_deg)\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "class Salton(WeightingScheme):\n",
    "    def __init__(self):\n",
    "        self.weight_type = 'global'\n",
    "\n",
    "\n",
    "    def score(self, x, y, G):\n",
    "        x_deg = scoped_degree(x,x,G)\n",
    "        y_deg = scoped_degree(y,x,G)\n",
    "        if x_deg != 0 and y_deg != 0:\n",
    "            return 1.0/math.sqrt(x_deg*y_deg)\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "def hub_depressed(validation_set, G):\n",
    "    \"\"\"\n",
    "    Find the hub promoted similarity of a single edge\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        x = non_edge[0]\n",
    "        y = non_edge[1]\n",
    "        cn = get_common_neighbors(x,y,G)\n",
    "        if scoped_out_degree(x, x, G) != 0 and scoped_in_degree(y, x, G) != 0:\n",
    "            s = 1.0*len(cn)/min(scoped_out_degree(x, x, G),scoped_in_degree(y, x, G))\n",
    "        else:\n",
    "            s = 0.0\n",
    "        non_edge[2]['score'] = s\n",
    "        results.append(non_edge)\n",
    "    return results\n",
    "\n",
    "def hub_promoted(validation_set, G):\n",
    "    \"\"\"\n",
    "    Find the hub promoted similarity of a single edge\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        x = non_edge[0]\n",
    "        y = non_edge[1]\n",
    "        cn = get_common_neighbors(x,y,G)\n",
    "        if scoped_out_degree(x, x, G) != 0 or scoped_in_degree(y, x, G) != 0:\n",
    "            s = 1.0*len(cn)/max(scoped_out_degree(x, x, G),scoped_in_degree(y, x, G))\n",
    "        else:\n",
    "            s = 0.0\n",
    "        non_edge[2]['score'] = s\n",
    "        results.append(non_edge)\n",
    "    return results\n",
    "\n",
    "def salton(validation_set, G):\n",
    "    \"\"\"\n",
    "    Find the salton similarity of a single edge\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        x = non_edge[0]\n",
    "        y = non_edge[1]\n",
    "        cn = get_common_neighbors(x,y,G)\n",
    "        if scoped_out_degree(x, x, G) == 0 or scoped_in_degree(y, x, G) == 0:\n",
    "            s = 0.0\n",
    "        else:\n",
    "            s = 1.0*len(cn)/math.sqrt(scoped_out_degree(x, x, G)*scoped_in_degree(y, x, G))\n",
    "        non_edge[2]['score'] = s\n",
    "        results.append(non_edge)\n",
    "    return results\n",
    "\n",
    "def leicht_holme_newman(validation_set, G):\n",
    "    \"\"\"\n",
    "    Perform LHN1 scoring on a single edge\n",
    "    \n",
    "    arguments:\n",
    "    non_edge -- edge tuple specified by node endpoints\n",
    "    G -- graph containing the nodes in the edge\n",
    "    \n",
    "    return:\n",
    "    edges with the score as an attribute\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        x = non_edge[0]\n",
    "        y = non_edge[1]\n",
    "        cn = get_common_neighbors(x,y,G)\n",
    "        if scoped_out_degree(x, x, G) == 0 or scoped_in_degree(y, x, G) == 0:\n",
    "            s = 0.0\n",
    "        else:\n",
    "            s = 1.0*len(cn)/(scoped_out_degree(x, x, G)*scoped_in_degree(y, x, G))\n",
    "        non_edge[2]['score'] = s\n",
    "        results.append(non_edge)\n",
    "    return results\n",
    "\n",
    "def adamic_adar(validation_set, G):\n",
    "    \"\"\"\n",
    "    Perform jaccard scoring on a list of edges\n",
    "    \n",
    "    arguments:\n",
    "    validation_set -- list of edges to score\n",
    "    G -- digraph containing the nodes in the edges of the validation set\n",
    "    \n",
    "    returns:\n",
    "    list of edges with score as an attribute\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        x = non_edge[0]\n",
    "        y = non_edge[1]\n",
    "        neighbors = get_common_neighbors(x,y,G)\n",
    "        s = -1*sum([1.0/math.log(scoped_degree(node, x, G)) for node in neighbors if scoped_degree(node, x, G) > 1])\n",
    "        non_edge[2]['score'] = s\n",
    "        results.append(non_edge)\n",
    "    return results\n",
    "\n",
    "def resource_allocation(validation_set, G):\n",
    "    \"\"\"\n",
    "    Perform resource allocation scoring on a list of edges\n",
    "    \n",
    "    arguments:\n",
    "    validation_set -- list of edges to score\n",
    "    G -- digraph containing the nodes in the edges of the validation set\n",
    "    \n",
    "    returns:\n",
    "    list of edges with score as an attribute\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        x = non_edge[0]\n",
    "        y = non_edge[1]\n",
    "        neighbors = get_common_neighbors(x,y,G)\n",
    "        s = sum([1.0/scoped_degree(node, x, G) for node in neighbors if scoped_degree(node, x, G) > 1])\n",
    "        non_edge[2]['score'] = s\n",
    "        results.append(non_edge)\n",
    "    return results\n",
    "\n",
    "\n",
    "def preferential_attachment(validation_set, G):\n",
    "    \"\"\"\n",
    "    Perform preferential attachment scoring on a list of edges\n",
    "    \n",
    "    arguments:\n",
    "    validation_set -- list of edges to score\n",
    "    G -- digraph containing the nodes in the edges of the validation set\n",
    "    \n",
    "    returns:\n",
    "    list of edges with score as an attribute\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "    for non_edge in validation_set:\n",
    "        x = non_edge[0]\n",
    "        y = non_edge[1]\n",
    "        s = scoped_out_degree(x,x,G)*scoped_in_degree(y,x,G)\n",
    "        non_edge[2]['score'] = s\n",
    "        results.append(non_edge)\n",
    "    return results\n",
    "\n",
    "def triadic_closeness(validation_set, G, census=None, weighting_scheme=None):\n",
    "    \n",
    "    results = []\n",
    "    if census == None:\n",
    "        census = triadic_distribution(G)\n",
    "    for non_edge in validation_set:\n",
    "        \n",
    "        x = non_edge[0]\n",
    "        y = non_edge[1]\n",
    "        connected = y in G[x]\n",
    "        if connected:\n",
    "            G.remove_edge(x,y)\n",
    "        u = set(scoped_neighborhood(x,x,G))\n",
    "        v = set(scoped_neighborhood(y,x,G))\n",
    "        cn = u.intersection(v)\n",
    "        t_score = []\n",
    "        for z in cn:\n",
    "            triad = get_triad(x,z,y,G)\n",
    "            if census[triad] == 0:\n",
    "                continue\n",
    "            try:\n",
    "                F2 = census[triad+30]\n",
    "            except KeyError:\n",
    "                F2 = 0.0\n",
    "            try:\n",
    "                F1 = census[triad+10]\n",
    "            except KeyError:\n",
    "                F1 = 0.0\n",
    "            \n",
    "            # Add in any weighting schemes that work on the individual nodes in the common neighborhood\n",
    "            if weighting_scheme and weighting_scheme.is_local():\n",
    "                score = weighting_scheme.score(z, x, GCC)*(1.0*F1 + F2)/census[triad]\n",
    "            else:\n",
    "                score = (1.0*F1 + F2)/census[triad]\n",
    "            \n",
    "            t_score.append(score)\n",
    "        s = sum(t_score)\n",
    "        if weighting_scheme and weighting_scheme.is_global():\n",
    "            s = s*weighting_scheme.score(x, y, G)\n",
    "        if len(non_edge) > 2:\n",
    "            non_edge[2]['score'] = s\n",
    "            results.append(non_edge)\n",
    "        else:\n",
    "            results.append(s)\n",
    "        if connected:\n",
    "            G.add_edge(x,y)\n",
    "    return results\n",
    "\n",
    "def triadic_distribution(G):\n",
    "    \"\"\"\n",
    "    Return the distribution of closed triad configurations for a graph\n",
    "    The distribution is labelled as in the paper by Schall\n",
    "    http://link.springer.com.proxy.findit.dtu.dk/article/10.1007/s13278-014-0157-9\n",
    "    \n",
    "    arguments:\n",
    "    G -- directed graph\n",
    "    \n",
    "    returns:\n",
    "    Dict of labels with counts\n",
    "    \"\"\"\n",
    "    \n",
    "    # Integer labels as presented in the paper\n",
    "    TRIAD_NAMES = range(1,10) + range(11, 20) + range(21,30) + range (31, 40)\n",
    "    census = {name: 0 for name in TRIAD_NAMES}\n",
    "    for u in G.nodes_iter():\n",
    "        u_neighbors = list(set(G.successors(u)) | set(G.predecessors(u)))\n",
    "        for z in u_neighbors:\n",
    "            z_neighbors = list((set(G.successors(z)) | set(G.predecessors(z))) - {u} )\n",
    "            for v in z_neighbors:\n",
    "                name = get_triad(u,z,v, G)\n",
    "                census[name] += 1\n",
    "    return census\n",
    "\n",
    "\n",
    "def get_triad(u,z,v,G):\n",
    "    \"\"\"\n",
    "    Return the triad created by the nodes u,v and z\n",
    "    This implementation is quite probably awful.\n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    u -- starting node\n",
    "    z -- connecting node\n",
    "    v -- ending node\n",
    "    G -- DiGraph containing the nodes\n",
    "    \n",
    "    returns:\n",
    "    Dict containing closed triad counts\n",
    "    \"\"\"\n",
    "    \n",
    "    u_out = G[u]\n",
    "    v_out = G[v]\n",
    "    z_out = G[z]\n",
    "    id = 0\n",
    "    \n",
    "    if v in u_out and u in v_out:\n",
    "        id = 30\n",
    "    elif u in v_out:\n",
    "        id = 20\n",
    "    elif v in u_out:\n",
    "        id = 10\n",
    "    \n",
    "    if u in z_out and z not in u_out:\n",
    "        id += 7\n",
    "        if v in z_out and z not in v_out:\n",
    "            return id + 2\n",
    "        elif z in v_out and v not in z_out:\n",
    "            return id + 1\n",
    "        elif z in v_out and v in z_out:\n",
    "            return id\n",
    "        raise Exception(\"Error in finding triad\")\n",
    "    elif z in v_out and v not in z_out:\n",
    "        id += 5\n",
    "        if z in u_out and u not in z_out:\n",
    "            return id + 1\n",
    "        elif z in u_out and u in z_out:\n",
    "            return id\n",
    "        raise Exception(\"Error in finding triad\")\n",
    "    elif z in u_out and u not in z_out:\n",
    "        id += 3\n",
    "        if v in z_out and z not in v_out:\n",
    "            return id + 1\n",
    "        if v in z_out and z in v_out:\n",
    "            return id\n",
    "        raise Exception(\"Error in finding triad\")\n",
    "    elif z in u_out and u in z_out:\n",
    "        if v in z_out and z not in v_out:\n",
    "            return id + 2\n",
    "        elif v in z_out and z in v_out:\n",
    "            return id + 1\n",
    "    \n",
    "    raise Exception(\"No triad found\")\n",
    "        \n",
    "\n",
    "def get_closed_triads(x, y, G):\n",
    "    \"\"\"\n",
    "    Return the closed triads generated by adding a link from x to y.\n",
    "    Triads are classified according to the triadic_census algorithm of NetworkX based on \n",
    "    http://vlado.fmf.uni-lj.si/pub/networks/doc/triads/triads.pdf\n",
    "    \"\"\"\n",
    "    \n",
    "    # Taken directly from nx.triadic_census source\n",
    "    TRIAD_NAMES = ('003', '012', '102', '021D', '021U', '021C', '111D', '111U',\n",
    "                   '030T', '030C', '201', '120D', '120U', '120C', '210', '300')\n",
    "    census = {name: 0 for name in TRIAD_NAMES}\n",
    "    \n",
    "    x_in = set(G.predecessors(x))\n",
    "    y_in = set(G.predecessors(y))\n",
    "    x_out = set(G.successors(x))\n",
    "    y_out = set(G.successors(y))\n",
    "    \n",
    "    for node in x_in | y_in | x_out | y_out:\n",
    "        # y refers to a node that refers to x\n",
    "        if node in x_in and node in y_out:\n",
    "            census['030C'] += 1\n",
    "        # y is being referred to by a node that refers to x\n",
    "        if node in x_in and node in y_in:\n",
    "            census['030T'] += 1\n",
    "        # x refers to a node that refers to y\n",
    "        if node in x_out and node in y_in:\n",
    "            census['030T'] += 1\n",
    "        # x refers to a node that y refers to\n",
    "        if node in x_out and node in y_out:\n",
    "            census['030T'] += 1\n",
    "\n",
    "def time_difference(candidate_edges, G):\n",
    "    \"\"\"\n",
    "    Return the time difference for a set of edges\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    results = [(x,y, {'score': int((G.node[x]['date'] - G.node[y]['date']).days)}) for x,y,_ in candidate_edges]\n",
    "    return results\n",
    "\n",
    "def shortest_dag_path(candidate_edges, G):\n",
    "    results = []\n",
    "    longest_possible_path = len(G.nodes())\n",
    "    for x,y,_ in candidate_edges:\n",
    "        connected = y in G[x].keys()\n",
    "        if connected:\n",
    "            G.remove_edge(x,y)\n",
    "        try:\n",
    "            results.append((x,y,{'score': nx.shortest_path_length(G,x,y)}))\n",
    "        except:\n",
    "            results.append((x,y, {'score': longest_possible_path}))\n",
    "        if connected:\n",
    "            G.add_edge(x,y)\n",
    "    return results\n",
    "        \n",
    "class CommonNeighbors():\n",
    "    \"\"\"\n",
    "    An experiment that scores a list of edges based on the number of common neighbors between the source and the target node\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, weighting_scheme=None):\n",
    "        self.weighting_scheme = weighting_scheme\n",
    "        \n",
    "    def valid_false_edges(self, G, source_nodes):\n",
    "        \"\"\"\n",
    "        Returns a list of edges that do not exist in G and will score highly on the common neighbors index\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        G: networkX.Graph\n",
    "            Graph to perform experiment on\n",
    "        source_nodes: list of tuples\n",
    "            Nodes containing the true edges to be scored\n",
    "        \"\"\"\n",
    "        false_validation_edges = [(source, target) for source in source_nodes\n",
    "                   for neighbor in G[source].keys()\n",
    "                   for target in set(scoped_neighborhood(neighbor, source, G)) - {source} if target not in G[source].keys()]\n",
    "        \n",
    "        false_validation_edges = list(set(false_validation_edges))\n",
    "        for i in range(len(false_validation_edges)):\n",
    "            edge = false_validation_edges[i]\n",
    "            # Add date information to the non-edge\n",
    "            false_validation_edges[i] = edge + ({'date': G.node[edge[0]]['date']},)\n",
    "        \n",
    "        return false_validation_edges\n",
    "        \n",
    "    def score_edges(self, edges, G):\n",
    "        return common_neighbors(edges, G, self.weighting_scheme)\n",
    "    \n",
    "class TriadicCloseness(CommonNeighbors):\n",
    "    \n",
    "    def __init__(self, cache_distribution=False, weighting_scheme=None):\n",
    "        self.cache_distribution = cache_distribution\n",
    "        self.census = None\n",
    "        self.weighting_scheme=weighting_scheme\n",
    "    \n",
    "    def score_edges(self, edges, G):\n",
    "        \n",
    "        if self.cache_distribution == True and self.census == None:\n",
    "            self.census = triadic_distribution(G)\n",
    "            return triadic_closeness(edges, G, self.census, self.weighting_scheme)\n",
    "        else:\n",
    "            return triadic_closeness(edges, G, self.census, self.weighting_scheme)\n",
    "    \n",
    "class CommonReferrers():\n",
    "    \n",
    "    def __init__(self, weighting_scheme=None):\n",
    "        self.weighting_scheme = weighting_scheme\n",
    "    \n",
    "    def valid_false_edges(self, G, source_nodes):\n",
    "        \"\"\"\n",
    "        Returns a list of edges that do not exist in G and will score highly on the common referrers index\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        G: networkX.Graph\n",
    "            Graph to perform experiment on\n",
    "        source_nodes: list of tuples\n",
    "            Nodes containing the true edges to be scored\n",
    "        \"\"\"\n",
    "        non_edges = []\n",
    "        for source in source_nodes:\n",
    "            neighbors = G[source].keys()\n",
    "            corefs = set()\n",
    "            for neighbor in neighbors:\n",
    "                corefs = corefs | {c for c in predecessors_scoped(neighbor, source, G)}\n",
    "            [non_edges.append((source, referee)) for coref in (corefs - {source}) \n",
    "                                                 for referee in set(successors_scoped(coref, source, G)) - set(neighbors)]\n",
    "            \n",
    "        for i in range(len(non_edges)):\n",
    "            edge = non_edges[i]\n",
    "            # Add date information to the non-edge\n",
    "            non_edges[i] = edge + ({'date': G.node[edge[0]]['date']},)\n",
    "        \n",
    "        return non_edges\n",
    "    \n",
    "    def score_edges(self, edges, G):\n",
    "        return common_referrers(edges, G, self.weighting_scheme)\n",
    "            \n",
    "                \n",
    "def valid_random_non_edges(graph, n):\n",
    "    \"\"\"\n",
    "    Returns randomized, non-existent links between nodes in the graph that are guaranteed to observe causality.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : NetworkX graph.\n",
    "        Graph to find non-existent edges.\n",
    "    n : integer\n",
    "        Number of non-existent edges to find\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    non_edges : list\n",
    "        List of n edges that are not in the graph.\n",
    "    \"\"\"\n",
    "    result_pairs = {}\n",
    "    # Sort edges according to age\n",
    "    sorted_edges =[node for node, data in sorted(graph.nodes(data=True), key=lambda x: x[1]['date'], reverse=True)]\n",
    "    node_set = set(graph.nodes())\n",
    "    candidates = list(np.random.choice(sorted_edges, n, replace=True))\n",
    "    i = 0\n",
    "    while i < len(candidates):\n",
    "        u = candidates[i]\n",
    "        if not u in result_pairs.keys():\n",
    "            result_pairs[u] = []\n",
    "            \n",
    "        # Make sure the potential neighbors respect causality with a resolution equal to the timestamp\n",
    "        cand_index = sorted_edges.index(u)\n",
    "        potential_neighbors = set(sorted_edges[cand_index:])\n",
    "        if graph.is_directed():\n",
    "            neighbors = set(graph.successors(u)).union(set(graph.predecessors(u)))\n",
    "        else:\n",
    "            neighbors = set(graph.neighbors(u))\n",
    "        # Make sure the potential neighbors respect causality\n",
    "        non_neighbors = list(potential_neighbors - neighbors - set(result_pairs[u]))\n",
    "        # The oldest node will have a neighborhood of Ø, so add a new candidate to the list in that case\n",
    "        if len(non_neighbors) == 0:\n",
    "            candidates.append(random.choice(graph.nodes()))\n",
    "        else:    \n",
    "            result_pairs[u].append(random.choice(non_neighbors))\n",
    "        i += 1\n",
    "    \n",
    "    return [(k,v) for k, arr in result_pairs.iteritems() for v in arr]\n",
    "        \n",
    "\n",
    "def k_fold_validate(G, k, experiment):\n",
    "    \"\"\"\n",
    "    K-fold validation of some specified function\n",
    "    \n",
    "    arguments:\n",
    "    G -- Graph to perform the function on\n",
    "    k -- number of folds\n",
    "    fun -- function to be evaluated\n",
    "    kwargs -- arguments to be passed to the evaluated function\n",
    "    \n",
    "    return:\n",
    "    List of lists of scored predictions\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    validation_sets = []\n",
    "    edges = G.edges(data=True)\n",
    "    random.shuffle(edges)\n",
    "    # Find all edges that do not exist in the graph, but will return a high score\n",
    "    false_edges = experiment.valid_false_edges(G, G.nodes())\n",
    "    random.shuffle(false_edges)\n",
    "    M = len(false_edges)/k\n",
    "    # Find the number of true members in the validation set\n",
    "    N = len(edges)/k\n",
    "    for i in range(0,k):\n",
    "        validation_sets.append(edges[i*N:(i+1)*N] + false_edges[i*M:(i+1)*M])\n",
    "    for val_edges in validation_sets:\n",
    "        res = experiment.score_edges(val_edges, G)\n",
    "        # If not shuffled, subsequent sorting algorithms will always rank true edges higher than false edges when they have\n",
    "        # the same score\n",
    "        random.shuffle(res)\n",
    "        results.append(res)\n",
    "    return results\n",
    "\n",
    "def k_fold_nodes(G, k, experiment):\n",
    "    \"\"\"\n",
    "    Perform k-fold validation on the nodes of the graph.\n",
    "    This validation only tests relevant false edges, i.e. edges where we are fairly certain the score won't come out as 0.0\n",
    "    making it useful for precision / recall, but not for AUC. The true edges can still score 0.0\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    nodes = G.nodes()\n",
    "    random.shuffle(nodes)\n",
    "    N = len(nodes)/k\n",
    "    validation_sets = []\n",
    "    for i in range(0, k):\n",
    "        validation_sets.append(nodes[i*N:(i+1)*N])\n",
    "    for true_nodes in validation_sets:\n",
    "        # Validation sets consist of all possible the edges in \n",
    "        val_edges = [(source, target, G[source][target]) for source in true_nodes for target in G[source].keys()]\n",
    "        val_set = set((source, target) for (source, target, _) in val_edges)\n",
    "        G_train = G.copy()\n",
    "        G_train.remove_edges_from(val_edges)\n",
    "        false_validation_edges = experiment.valid_false_edges(G, true_nodes)\n",
    "        false_validation_edges = [(x,y,data) for (x,y,data) in false_validation_edges if (x,y) not in val_set]\n",
    "        validation_set = val_edges + false_validation_edges\n",
    "        # If not shuffled, subsequent sorting algorithms will always rank true edges higher than false edges when they have\n",
    "        # the same score\n",
    "        random.shuffle(validation_set)        \n",
    "        results.append(experiment.score_edges(validation_set, G))\n",
    "    return results\n",
    "\n",
    "def at_degree_validation(G, experiment, degree):\n",
    "    if degree < 2:\n",
    "        raise Exception('Degree must be larger than 2')\n",
    "    res = {}\n",
    "    H = G.copy()\n",
    "    to_be_evaluated = []\n",
    "    # Randomly sample n nodes from each degree bin\n",
    "    deg=nx.degree(G)\n",
    "    h = {}\n",
    "    for node in G.nodes_iter():\n",
    "        if G.out_degree(node) == degree:\n",
    "            to_be_evaluated.append(node)\n",
    "    for node in to_be_evaluated:\n",
    "        res[node] = []\n",
    "        e = G.edges(node, data=True)\n",
    "        if not len(e) == degree:\n",
    "            raise Exception(\"Mismatch: {}\".format(len(e)))\n",
    "        G.remove_edges_from(e[1:degree-1])\n",
    "        for i in range(1, degree):\n",
    "            to_be_scored = experiment.valid_false_edges(H, [node]) + e[i:degree]\n",
    "            random.shuffle(to_be_scored)\n",
    "            scored_edges = experiment.score_edges(to_be_scored, G)\n",
    "            [edge[2].update({'n_edges': i}) for edge in scored_edges]\n",
    "            res[node] += scored_edges\n",
    "            #res[node][i] = scored_edges\n",
    "            G.add_edge(e[i][0], e[i][1])\n",
    "    return res\n",
    "        \n",
    "def precision(G, results, L):\n",
    "    \"\"\"\n",
    "    Find the ratio of the true positives to trues\n",
    "    \n",
    "    arguments:\n",
    "    G -- graph the results are based on\n",
    "    results -- list of lists of scored predictions\n",
    "    L -- number of results to be considered\n",
    "    \n",
    "    return:\n",
    "    List of precisions for each set of results\n",
    "    \"\"\"\n",
    "    # Sort the results with descending scores\n",
    "    results = [sorted(result, key=lambda x: x[2]['score'], reverse=True) for result in results]\n",
    "    for res in results:\n",
    "        if L > len(res):\n",
    "            raise ArgumentError(\"L is larger than the number of results\")\n",
    "    edge_set = set(G.edges())\n",
    "    # True positives exist in both the edge set and the result set\n",
    "    true_positives = [[(edge[0],edge[1]) for edge in result[0:L] if (edge[0], edge[1]) in edge_set] for result in results]\n",
    "    return [1.0*len(trues)/L for trues in true_positives]\n",
    "\n",
    "def per_node_precision(G, results):\n",
    "    \"\"\"\n",
    "    results : dict\n",
    "        A dict of {node: [e1, e2, ... e_n]} where e is an edge of the form (source, target, {'n_edges': x, 'score': y}) where\n",
    "        n_edges number of edges the node had when the prediction was made.\n",
    "    \"\"\"\n",
    "    \n",
    "    m = 43\n",
    "    # Create a dict that all the edges sorted by score and grouped by n_edges and then node\n",
    "    s = {n: {k: [] for k in range(1,m+1)} for n in results.iterkeys()}\n",
    "    for node, node_res in results.iteritems():\n",
    "        # Sort the entire list of results\n",
    "        srt = sorted(node_res, key=lambda x: x[2]['score'], reverse=True)\n",
    "        for x,y,data in srt:\n",
    "            # Add each result to its proper bin\n",
    "            s[node][data['n_edges']].append((x,y,{'score': data['score']}))\n",
    "    precisions = {k: [] for k in range(1,m+1)}\n",
    "    edge_set = set(G.edges())\n",
    "    for node, node_res in s.iteritems():\n",
    "        n = G.out_degree(node)\n",
    "        for level, results in node_res.iteritems():\n",
    "            L = n-level\n",
    "            if len(results) == 0:\n",
    "                break\n",
    "            precisions[level].append(1.0*len([(edge[0],edge[1]) for edge in results[0:L] if (edge[0], edge[1]) in edge_set])/L)\n",
    "    return precisions\n",
    "    \n",
    "\n",
    "def precision2(G, results, L):\n",
    "    \"\"\"\n",
    "    Find the ratio of the true positives to trues\n",
    "    \n",
    "    arguments:\n",
    "    G -- graph the results are based on\n",
    "    results -- list of lists of scored predictions\n",
    "    L -- number of results to be considered\n",
    "    \n",
    "    return:\n",
    "    List of precisions for each set of results\n",
    "    \"\"\"\n",
    "    # Sort the results with descending scores\n",
    "    #results = heapq.nlargest(L, results, key=lambda x: x[2]['score'])\n",
    "    edge_set = set(G.edges())\n",
    "    # True positives exist in both the edge set and the result set\n",
    "    true_positives = [(edge[0],edge[1]) for edge in results if (edge[0], edge[1]) in edge_set]\n",
    "    return 1.0*len(true_positives)/L\n",
    "\n",
    "def AUC(G, results):\n",
    "    \"\"\"\n",
    "    Perform n trials where the score of a non-edge and an edge in the result is compared. Count the number of trials where\n",
    "    the edge had the higher score as n' and the number of times the score was equal as n'' and return the AUC as (n' + n'')/n.\n",
    "    \n",
    "    arguments:\n",
    "    G -- graph the results are based on\n",
    "    results -- list of lists of scored predictions\n",
    "    \n",
    "    return:\n",
    "    List of precisions for each set of results\n",
    "    \"\"\"\n",
    "    \n",
    "    edge_set = set(G.edges())\n",
    "    AUC = []\n",
    "    for result_set in results:\n",
    "        true_edges = []\n",
    "        false_edges = []\n",
    "        for (x,y,data) in result_set:\n",
    "            if (x,y) in edge_set:\n",
    "                true_edges.append((x,y,data))\n",
    "            else:\n",
    "                false_edges.append((x,y,data))\n",
    "        \n",
    "        random.shuffle(true_edges)\n",
    "        random.shuffle(false_edges)\n",
    "        n = len(true_edges)\n",
    "        n_better = 0.0\n",
    "        n_same = 0.0\n",
    "        for i in range(0, n):\n",
    "            if true_edges[i][2]['score'] > false_edges[i][2]['score']:\n",
    "                n_better += 1.0\n",
    "            if true_edges[i][2]['score'] == false_edges[i][2]['score']:\n",
    "                n_same += 1.0\n",
    "        AUC.append((n_better + 0.5*n_same)/n)\n",
    "    return AUC\n",
    "\n",
    "def slice_graph_by_year(start_year, end_year, G):\n",
    "    \"\"\"\n",
    "    Returns all nodes created within a range of years\n",
    "    \"\"\"\n",
    "    if datetime.date(start_year, 1, 1) < datetime.date(end_year, 1, 1):\n",
    "        raise ArgumentError(\"The starting year must be larger than or equal to the ending year\")\n",
    "    t1 = datetime.date(start_year, 12, 31)\n",
    "    t2 = datetime.date(end_year, 1, 1)\n",
    "    \n",
    "    return [n for n in G.nodes(data=True) if n[1]['date'] >= t2 and n[1]['date'] < t1]\n",
    "\n",
    "f = lambda x, y, G: y in G[x].keys()\n",
    "features = ['edge',\n",
    "            'triadic_closeness',\n",
    "            'common_neighbors',\n",
    "            'time_difference',\n",
    "            'common_referrers',\n",
    "            'src_degree', \n",
    "            'trg_degree', \n",
    "            'degree_product',\n",
    "            'common_referrersadamic_adar',\n",
    "            'adamic_adar', \n",
    "            'leicht_holme_newman',\n",
    "            'resource_allocation']\n",
    "\n",
    "def get_features(G, cand_edges, year, load=True):\n",
    "    \n",
    "    def load_or_extract(function, f_name, year, cand_edges, G, load=True):\n",
    "        path = 'pickles/'+GRAPH+'_'+year+'_'+f_name+'.pkl'\n",
    "        if isfile(path) and load:\n",
    "            res = pd.read_pickle(path)\n",
    "        else:\n",
    "            res = pd.Series([data['score'] for _, __, data in function(cand_edges, G)])\n",
    "            if load:\n",
    "                res.to_pickle(path)\n",
    "        return res\n",
    "                              \n",
    "    df = pd.DataFrame(index=[(x,y) for x,y,_ in cand_edges])\n",
    "    true_edges = set(G.edges())\n",
    "    df['shortest_path'] = load_or_extract(shortest_dag_path, 'shortest_path', str(year), cand_edges, G, load).values\n",
    "    df['edge'] = [True if (x,y) in true_edges else False for x,y,_ in cand_edges]\n",
    "    df['source'] = [x for x,_,__ in cand_edges]\n",
    "    df['target'] = [y for _,y,__ in cand_edges]\n",
    "    df['triadic_closeness'] = load_or_extract(triadic_closeness, 'triadic_closeness', str(year), cand_edges, G, load).values\n",
    "    df['common_neighbors'] = load_or_extract(common_neighbors, 'common_neighbors', str(year), cand_edges, G, load).values\n",
    "    df['time_difference'] = load_or_extract(time_difference, 'time_difference', str(year), cand_edges, G, load).values\n",
    "    df['common_referrers'] = load_or_extract(common_referrers, 'common_referrers', str(year), cand_edges, G, load).values\n",
    "    df['src_degree'] = [len(G[x]) for x, _, __ in cand_edges]\n",
    "    df['trg_degree'] = [len(G[y]) for _, y, __ in cand_edges]\n",
    "    df['preferential_attachment'] = load_or_extract(preferential_attachment, 'preferential_attachment', \n",
    "                                                    str(year), cand_edges, G, load).values\n",
    "    df['adamic_adar'] = load_or_extract(adamic_adar, 'adamic_adar', str(year), cand_edges, G, load).values\n",
    "    df['leicht_holme_newman'] = load_or_extract(leicht_holme_newman, \n",
    "                                                'leicht_holme_newman', str(year), cand_edges, G, load).values\n",
    "    df['resource_allocation'] = load_or_extract(resource_allocation, \n",
    "                                                'resource_allocation', str(year), cand_edges, G, load).values\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "The large dataset makes prediction times very long and the class imbalance biases heavily toward predicting the negative class.\n",
    "\n",
    "### Class imbalance and data set size\n",
    "Since there are $V^2$ possible links between vertices and only a small part of them will turn out to be actual true links the dataset suffers highly from class imbalance, which for some classifiers can lead to solutions that are biased to predicting the majority class while others are perfectly able to handle imbalanced classes without bias.\n",
    "\n",
    "If it presents a problem class imbalance can be handled by\n",
    "* Weigthing the different classes to ensure that the minority class is given more importance.\n",
    "* Undersampling the majority class with replacement. This has the benefit of lower training and feature generation times, however important information in the majority class can be missed, leading to low classifier performance on the test set.\n",
    "* Upsampling the minority class with replacement. This method does not run the risk of missing information in the training set, but bias can still be introduced and computation time increases.\n",
    "\n",
    "These methods can be combined with the bootstrap technique where several classifiers are trained on different samples and predictions on the test set is a decided by majority voting.\n",
    "\n",
    "Weighting and undersampling have been used on the different methods, however with little "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Prepare a single year test set\n",
    "test_year = 2013\n",
    "nodes_test = [n[0] for n in slice_graph_by_year(test_year, test_year, GCC)]\n",
    "G_train = GCC.copy()\n",
    "G_train.remove_edges_from(nodes_test)\n",
    "test_candidates = [(source, target, {}) for target in GCC.nodes() for source in nodes_test if not source==target]\n",
    "test_data = get_features(GCC, test_candidates, test_year)\n",
    "y_test = test_data['edge']\n",
    "X_test = test_data.ix[:, [col for col in test_data.columns if col not in ['edge', 'source', 'target']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Prepare a multi-year training set, this is the full set of edges which will take a very long time to compute\n",
    "train_year = 2012\n",
    "nodes_train = [n[0] for n in slice_graph_by_year(train_year, train_year, G_train)]\n",
    "train_candidates = [(source, target, {}) for target in G_train.nodes() for source in nodes_train if not source==target]\n",
    "train_data = get_features(GCC, train_candidates, train_year)\n",
    "y_train = train_data['edge']\n",
    "X_train = train_data.ix[:, [col for col in train_data.columns if col not in ['edge', 'source', 'target']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ensure that there is no overlap between test and train set\n",
    "assert len(set([(x,y) for x,y,_ in train_candidates]).intersection(set([(x,y) for x,y,_ in test_candidates]))) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Methods\n",
    "\n",
    "Like in un-supervised learning, supervised learning in link prediction means finding a model that is able to predict whether two nodes will form a link based on other features of the network. The difference between the two is that supervised learning finds a model that explains the links already formed in a subset of the data, $G_{train}$ by combining different features such as common neighbors, node degree and node centrality and assign a weight to each feature according to its importance. This model can then be tested on the remaining data, $G_{test}$, and since this part of the network wasn't used to create the model it will give an unbiased result which can be used for evaluation.\n",
    "\n",
    "## Feature selection\n",
    "For the supervised model it is possible to use all the different features described earlier, such as Common Neighbors, Common Referrers and so on. In many cases however the features are quite similar, for example Adamic-Adar and Resource Allocation only differ in that Adamic-Adar takes the log of the denominator. Precision wise this is not necessarily a problem since the number of samples still is much greater than the number of features, but redundant features makes the model harder to interpret and if real-time results are expected in an implementation of the classifier the additional computational time might be noticable by the end user. \n",
    "For these reasons it is interesting to look at reducing the number of features used in the final model for which there are three general approaches (Hasties)\n",
    "* Subset selection which involves finding the smallest subset of features which leads to the model with the best predictive power. For $p$ features this means fitting $2^p$ models, so often the variant forward stepwise selection is used, leading to much smaller computational times (Hasties).\n",
    "* Feature shrinking involves adding a regularization term to the computation of the minimal Residual Sum of Squares (RSS) which reduces overfitting of the model and if L1-regularization is used it can even prune out redundant features.\n",
    "* Dimensionality reduction covers matrix factorization techniques such as Principal Component Analysis (PCA) and Independent Component Analysis. Both have the advantage of decreasing the feature space however the model is often harder to interpret since the original feature space is transformed and for this reason they are not considered for feature selection for this project.\n",
    "\n",
    "To identify either the best subset of features or the regularization parameter it is necessary to use cross validation or an adjusted RSS that takes model complexity into account like the Akaike Information Criterion (AIC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "In machine learning terms link prediction is a categorical problem since we are investigating the binary response to $x$ links to $y$ shown below\n",
    "$$\n",
    "    f(x,y)= \n",
    "\\begin{cases}\n",
    "    1,& \\text{if } x \\ \\text{links to} \\ y \\\\\n",
    "    0,              & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "There are many methods specifically suited to categorical variables in machine learning where logistic regression is among the simplest. It is comparable to linear regression which is used and suited for continuous variables, but instead of modeling a continuous response it models a probability of a response variable taking some discrete value, $P(\\text{link}_{x,y} \\ | \\ \\text{feature}_{x,y})$ (REF HASTIES). Since true probabilites fall between 0 and 1 the logistic function is used, which for a range of input variables returns an S-shaped curve asymptotically approaching 0 and 1 in either limit\n",
    "$$\n",
    "p(X) = \\frac{e^{\\beta_0+\\beta_1X}}{1+e^{\\beta_0+\\beta_1X}}\n",
    "$$\n",
    "where $\\beta$ is the trainable parameter and X is the input series. The output probability can then be evaluated to determine if a link is formed.\n",
    "Since link prediction can benefit from using several input variables instead of only one it is an advantage that logistic regression can be expanded to multiple logistic regression quite simply by simply adding an addtional $\\beta$ parameter for each additional input. As with single regression the parameters are trained using maximum likelihood methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Logistic Regression\n",
    "# Find hyper-parameters for the regressors\n",
    "# Try both L1 and L2 regularization with different coefficients\n",
    "param_grid = {'C': [10, 1000, 100000], 'penalty': ['l1', 'l2']}\n",
    "def scorer(ground_truth, predictions):\n",
    "    return average_precision_score(ground_truth, predictions[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time.clock()\n",
    "print(\"# Tuning hyper-parameters for AUC-PR\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    clf = pickle.load(open('pickles/log_grid_search.pkl', 'rb'))\n",
    "except:\n",
    "    # Do an exhaustive search of the entire grid\n",
    "    clf = GridSearchCV(LogisticRegression(), param_grid, cv=5,\n",
    "                       scoring=make_scorer(scorer, needs_proba=True))\n",
    "    clf.fit(X_train, y_train)\n",
    "    with open('pickles/log_grid_search.pkl', 'wb') as fl:\n",
    "        pickle.dump(clf, fl)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "for params, mean_score, scores in clf.grid_scores_:\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean_score, scores.std() * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "t1 = time.clock()\n",
    "print \"Running time: {}\".format(t1-t0)\n",
    "logistic_regression_params = clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_model = SelectFromModel(clf.best_estimator_, prefit=True)\n",
    "X_new = new_model.transform(X_train)\n",
    "print \"Dimensions of old model: {}\".format(X_train.shape)\n",
    "print \"Dimensions of model transformed after L1 regularization: {}\".format(X_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoMAAAEZCAYAAADsey82AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUq8AAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x303506128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_model = LogisticRegression(C=10000, penalty='l1')\n",
    "log_model.fit(X_train, y_train)\n",
    "preds = log_model.predict_proba(X_test)\n",
    "mean_avg_precision = average_precision_score(y_test, preds[:,1])\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, preds[:,1])\n",
    "plt.plot(recall, precision, lw=1, label='Avg. preceision {}'.format(mean_avg_precision))\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision and Recall for logistic regression')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       1.00      0.98      0.99   3511712\n",
      "       True       0.03      0.83      0.06      3218\n",
      "\n",
      "avg / total       1.00      0.98      0.99   3514930\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, log_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shortest_path: -3.28071765314e-06\n",
      "triadic_closeness: 0.523519512229\n",
      "common_neighbors: -6.91525239262\n",
      "time_difference: -0.000184663323347\n",
      "common_referrers: 0.900488515432\n",
      "src_degree: 0.020855872363\n",
      "trg_degree: 0.0280838753315\n",
      "preferential_attachment: 0.00307733379662\n",
      "adamic_adar: -35.6331272821\n",
      "leicht_holme_newman: 28.4174671164\n",
      "resource_allocation: -51.3757820536\n"
     ]
    }
   ],
   "source": [
    "for name, coef in zip(X_train.columns.values, log_model.coef_[0]):\n",
    "    print '{}: {}'.format(name, coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision trees\n",
    "A decision tree is a rule based classifier which can be seen as determining the class of a sample by asking questions to the features such as, *\"If there are more than 4 common neighbors, classify it is as a link\"* and combining these rules to divide the feature space into regions of different classes. Normally these rules are created by a top-down algorithm which greedily splits the training data based on what split gives the largest decrease in RSS after which the same procedure is recursively applied to the two new partitions, ad nauseam until some stopping criterion is reached.\n",
    "\n",
    "This leads to a set of rules that will be very good at predicting the training set, however it has a high likelihood of overfitting so usually this larger tree is pruned down in a manner similar to regularization in general linear models which reduces variance at the cost of some bias in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_selection import RFECV\n",
    "clf = RandomForestClassifier()\n",
    "rfe_forest = RFECV(estimator=clf, step=1, scoring=make_scorer(scorer, needs_proba=True))\n",
    "rfe_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Included and excluded features\n",
      "shortest_path: True\n",
      "triadic_closeness: True\n",
      "common_neighbors: True\n",
      "time_difference: True\n",
      "common_referrers: True\n",
      "src_degree: True\n",
      "trg_degree: True\n",
      "preferential_attachment: True\n",
      "adamic_adar: True\n",
      "leicht_holme_newman: True\n",
      "resource_allocation: True\n"
     ]
    }
   ],
   "source": [
    "print \"Included and excluded features\"\n",
    "for name, state in zip(X_train.columns.values, rfe_forest.support_):\n",
    "    print '{}: {}'.format(name, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       1.00      1.00      1.00   3511712\n",
      "       True       0.50      0.14      0.22      3218\n",
      "\n",
      "avg / total       1.00      1.00      1.00   3514930\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, rfe_forest.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shortest_path: Included\n",
      "triadic_closeness: Included\n",
      "common_neighbors: Included\n",
      "time_difference: Included\n",
      "common_referrers: Included\n",
      "src_degree: Included\n",
      "trg_degree: Included\n",
      "preferential_attachment: Included\n",
      "adamic_adar: Included\n",
      "leicht_holme_newman: Included\n",
      "resource_allocation: Included\n"
     ]
    }
   ],
   "source": [
    "in_out = ['Excluded', 'Included']\n",
    "for name, in_model in sorted(zip(X_train.columns.values, rfe_forest.get_support()), key=lambda tup: tup[1], reverse=True):\n",
    "    print name + \": {}\".format(in_out[in_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoMAAAEZCAYAAADsey82AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x212e79e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = rfe_forest.predict_proba(X_test)\n",
    "mean_avg_precision = average_precision_score(y_test, preds[:,1])\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, preds[:,1])\n",
    "plt.plot(recall, precision, lw=1, label='Avg. preceision {}'.format(mean_avg_precision))\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision and Recall for a random forest classifier')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoMAAAEZCAYAAADsey82AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21f24908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Included and excluded features:\n",
      "shortest_path: Included\n",
      "triadic_closeness: Included\n",
      "common_neighbors: Excluded\n",
      "time_difference: Included\n",
      "common_referrers: Included\n",
      "src_degree: Included\n",
      "trg_degree: Included\n",
      "preferential_attachment: Included\n",
      "adamic_adar: Included\n",
      "leicht_holme_newman: Included\n",
      "resource_allocation: Included\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       1.00      1.00      1.00   3511712\n",
      "       True       0.20      0.24      0.22      3218\n",
      "\n",
      "avg / total       1.00      1.00      1.00   3514930\n",
      "\n",
      "Wall time: 4min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rfe_tree = RFECV(estimator=tree.DecisionTreeClassifier(), step=1, scoring=make_scorer(scorer, needs_proba=True))\n",
    "rfe_tree.fit(X_train, y_train)\n",
    "preds = rfe_tree.predict_proba(X_test)\n",
    "mean_avg_precision = average_precision_score(y_test, preds[:,1])\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, preds[:,1])\n",
    "plt.plot(recall, precision, lw=1, label='Avg. preceision {}'.format(mean_avg_precision))\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision and Recall for a single decision tree')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "print\n",
    "print \"Included and excluded features:\"\n",
    "in_out = ['Excluded', 'Included']\n",
    "for name, in_model in zip(X_train.columns.values, rfe_tree.get_support()):\n",
    "    print name + \": {}\".format(in_out[in_model])\n",
    "print\n",
    "print classification_report(y_test, rfe_tree.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export the tree\n",
    "dot_data = StringIO()\n",
    "tree.export_graphviz(rfe_tree.estimator_, out_file=dot_data,  \n",
    "                         feature_names=X_train.columns.values[rfe_tree.support_],  \n",
    "                         class_names=['No link', 'Link'],  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) \n",
    "graph.write_pdf(\"rfe_tree.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=20, class_weight='balanced')\n",
    "random_forest.fit(X_train, y_train)\n",
    "preds = random_forest.predict_proba(X_test)\n",
    "mean_avg_precision = average_precision_score(y_test, preds[:,1])\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, preds[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAngAAAEZCAYAAAAE11hYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNKOAJyIiIpJmFPBERERE0sz/B4TxELtACBfuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x280e4e3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(recall, precision, lw=1, label='Avg. precision: {}'.format(mean_avg_precision))\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision and Recall for random forest, 20 trees')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       1.00      1.00      1.00   3511712\n",
      "       True       0.38      0.09      0.15      3218\n",
      "\n",
      "avg / total       1.00      1.00      1.00   3514930\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, random_forest.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with unsupervised methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run load_data.py\n",
    "GRAPH = 'EUCHR'\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "# Find the greatest connected component and work on that\n",
    "components = []\n",
    "lengths = []\n",
    "# Find the greatest component from the undirected version of the graph\n",
    "for component in nx.connected_component_subgraphs(nx.Graph(G)):\n",
    "    components.append(component)\n",
    "    lengths.append(len(component))\n",
    "# Find the GCC as the largest component and then recreate the directed graph\n",
    "GCC = components[lengths.index(max(lengths))]\n",
    "GCC = G.subgraph(GCC.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node done: 62012CJ0009\n",
      "Node done: 62012CJ0353\n",
      "Node done: 62011CJ0360\n",
      "Node done: 62011CJ0576\n",
      "Node done: 62012CJ0321\n",
      "Node done: 62011CJ0575\n",
      "Node done: 62011CJ0246\n",
      "Node done: 62012CJ0079\n",
      "Node done: 62011CJ0533\n",
      "Node done: 62012CJ0111\n",
      "Node done: 62012CJ0137\n",
      "Node done: 62011CJ0425\n",
      "Node done: 62011CJ0626\n",
      "Node done: 62011CJ0435\n",
      "Node done: 62012CJ0281\n",
      "Node done: 62011CJ0604\n",
      "Node done: 62011CJ0065\n",
      "Node done: 62012CJ0523\n",
      "Node done: 62011CJ0595\n",
      "Node done: 62012CJ0274\n",
      "Node done: 62010CJ0480\n",
      "Node done: 62012CJ0272\n",
      "Node done: 62012CJ0010\n",
      "Node done: 62012CJ0187\n",
      "Node done: 62011CJ0375\n",
      "Node done: 62012CJ0279\n",
      "Node done: 62011CJ0275\n",
      "Node done: 62012CJ0109\n",
      "Node done: 62012CJ0225\n",
      "Node done: 62011CJ0011\n",
      "Node done: 62011CJ0546\n",
      "Node done: 62012CJ0095\n",
      "Node done: 62012CJ0091\n",
      "Node done: 62012CJ0298\n",
      "Node done: 62010CJ0627\n",
      "Node done: 62011CJ0396\n",
      "Node done: 62011CJ0282\n",
      "Node done: 62012CJ0062\n",
      "Node done: 62011CJ0529\n",
      "Node done: 62011CJ0243\n",
      "Node done: 62013CJ0168\n",
      "Degree done: 5\n",
      "Node done: 62012CJ0001\n",
      "Node done: 62012CJ0344\n",
      "Node done: 62012CJ0309\n",
      "Node done: 62012CJ0265\n",
      "Node done: 62012CJ0006\n",
      "Node done: 62011CJ0186\n",
      "Node done: 62011CJ0361\n",
      "Node done: 62012CJ0221\n",
      "Node done: 62012CJ0113\n",
      "Node done: 62011CJ0415\n",
      "Node done: 62011CJ0287\n",
      "Node done: 62012CJ0282\n",
      "Node done: 62012CJ0440\n",
      "Node done: 62012CJ0180\n",
      "Node done: 62012CJ0058\n",
      "Node done: 62011CJ0092\n",
      "Node done: 62012CJ0184\n",
      "Node done: 62012CJ0273\n",
      "Node done: 62012CJ0425\n",
      "Node done: 62011CJ0212\n",
      "Node done: 62011CJ0210\n",
      "Node done: 62012CJ0124\n",
      "Node done: 62012CJ0099\n",
      "Node done: 62012CJ0319\n",
      "Node done: 62011CJ0397\n",
      "Node done: 62011CJ0073\n",
      "Node done: 62011CJ0630\n",
      "Node done: 62010CJ0383\n",
      "Node done: 62009CJ0529\n",
      "Degree done: 10\n",
      "Node done: 62011CJ0224\n",
      "Node done: 62011CJ0548\n",
      "Node done: 62011CJ0168\n",
      "Node done: 62012CJ0116\n",
      "Degree done: 15\n",
      "Node done: 62011CJ0350\n",
      "Node done: 62010CJ0584\n",
      "Degree done: 20\n",
      "Model done: single_tree\n",
      "Node done: 62012CJ0009\n",
      "Node done: 62012CJ0353\n",
      "Node done: 62011CJ0360\n",
      "Node done: 62011CJ0576\n",
      "Node done: 62012CJ0321\n",
      "Node done: 62011CJ0575\n",
      "Node done: 62011CJ0246\n",
      "Node done: 62012CJ0079\n",
      "Node done: 62011CJ0533\n",
      "Node done: 62012CJ0111\n",
      "Node done: 62012CJ0137\n",
      "Node done: 62011CJ0425\n",
      "Node done: 62011CJ0626\n",
      "Node done: 62011CJ0435\n",
      "Node done: 62012CJ0281\n",
      "Node done: 62011CJ0604\n",
      "Node done: 62011CJ0065\n",
      "Node done: 62012CJ0523\n",
      "Node done: 62011CJ0595\n",
      "Node done: 62012CJ0274\n",
      "Node done: 62010CJ0480\n",
      "Node done: 62012CJ0272\n",
      "Node done: 62012CJ0010\n",
      "Node done: 62012CJ0187\n",
      "Node done: 62011CJ0375\n",
      "Node done: 62012CJ0279\n",
      "Node done: 62011CJ0275\n",
      "Node done: 62012CJ0109\n",
      "Node done: 62012CJ0225\n",
      "Node done: 62011CJ0011\n",
      "Node done: 62011CJ0546\n",
      "Node done: 62012CJ0095\n",
      "Node done: 62012CJ0091\n",
      "Node done: 62012CJ0298\n",
      "Node done: 62010CJ0627\n",
      "Node done: 62011CJ0396\n",
      "Node done: 62011CJ0282\n",
      "Node done: 62012CJ0062\n",
      "Node done: 62011CJ0529\n",
      "Node done: 62011CJ0243\n",
      "Node done: 62013CJ0168\n",
      "Degree done: 5\n",
      "Node done: 62012CJ0001\n",
      "Node done: 62012CJ0344\n",
      "Node done: 62012CJ0309\n",
      "Node done: 62012CJ0265\n",
      "Node done: 62012CJ0006\n",
      "Node done: 62011CJ0186\n",
      "Node done: 62011CJ0361\n",
      "Node done: 62012CJ0221\n",
      "Node done: 62012CJ0113\n",
      "Node done: 62011CJ0415\n",
      "Node done: 62011CJ0287\n",
      "Node done: 62012CJ0282\n",
      "Node done: 62012CJ0440\n",
      "Node done: 62012CJ0180\n",
      "Node done: 62012CJ0058\n",
      "Node done: 62011CJ0092\n",
      "Node done: 62012CJ0184\n",
      "Node done: 62012CJ0273\n",
      "Node done: 62012CJ0425\n",
      "Node done: 62011CJ0212\n",
      "Node done: 62011CJ0210\n",
      "Node done: 62012CJ0124\n",
      "Node done: 62012CJ0099\n",
      "Node done: 62012CJ0319\n",
      "Node done: 62011CJ0397\n",
      "Node done: 62011CJ0073\n",
      "Node done: 62011CJ0630\n",
      "Node done: 62010CJ0383\n",
      "Node done: 62009CJ0529\n",
      "Degree done: 10\n",
      "Node done: 62011CJ0224\n",
      "Node done: 62011CJ0548\n",
      "Node done: 62011CJ0168\n",
      "Node done: 62012CJ0116\n",
      "Degree done: 15\n",
      "Node done: 62011CJ0350\n",
      "Node done: 62010CJ0584\n",
      "Degree done: 20\n",
      "Model done: random_forest\n",
      "Node done: 62012CJ0009\n",
      "Node done: 62012CJ0353\n",
      "Node done: 62011CJ0360\n",
      "Node done: 62011CJ0576\n",
      "Node done: 62012CJ0321\n",
      "Node done: 62011CJ0575\n",
      "Node done: 62011CJ0246\n",
      "Node done: 62012CJ0079\n",
      "Node done: 62011CJ0533\n",
      "Node done: 62012CJ0111\n",
      "Node done: 62012CJ0137\n",
      "Node done: 62011CJ0425\n",
      "Node done: 62011CJ0626\n",
      "Node done: 62011CJ0435\n",
      "Node done: 62012CJ0281\n",
      "Node done: 62011CJ0604\n",
      "Node done: 62011CJ0065\n",
      "Node done: 62012CJ0523\n",
      "Node done: 62011CJ0595\n",
      "Node done: 62012CJ0274\n",
      "Node done: 62010CJ0480\n",
      "Node done: 62012CJ0272\n",
      "Node done: 62012CJ0010\n",
      "Node done: 62012CJ0187\n",
      "Node done: 62011CJ0375\n",
      "Node done: 62012CJ0279\n",
      "Node done: 62011CJ0275\n",
      "Node done: 62012CJ0109\n",
      "Node done: 62012CJ0225\n",
      "Node done: 62011CJ0011\n",
      "Node done: 62011CJ0546\n",
      "Node done: 62012CJ0095\n",
      "Node done: 62012CJ0091\n",
      "Node done: 62012CJ0298\n",
      "Node done: 62010CJ0627\n",
      "Node done: 62011CJ0396\n",
      "Node done: 62011CJ0282\n",
      "Node done: 62012CJ0062\n",
      "Node done: 62011CJ0529\n",
      "Node done: 62011CJ0243\n",
      "Node done: 62013CJ0168\n",
      "Degree done: 5\n",
      "Node done: 62012CJ0001\n",
      "Node done: 62012CJ0344\n",
      "Node done: 62012CJ0309\n",
      "Node done: 62012CJ0265\n",
      "Node done: 62012CJ0006\n",
      "Node done: 62011CJ0186\n",
      "Node done: 62011CJ0361\n",
      "Node done: 62012CJ0221\n",
      "Node done: 62012CJ0113\n",
      "Node done: 62011CJ0415\n",
      "Node done: 62011CJ0287\n",
      "Node done: 62012CJ0282\n",
      "Node done: 62012CJ0440\n",
      "Node done: 62012CJ0180\n",
      "Node done: 62012CJ0058\n",
      "Node done: 62011CJ0092\n",
      "Node done: 62012CJ0184\n",
      "Node done: 62012CJ0273\n",
      "Node done: 62012CJ0425\n",
      "Node done: 62011CJ0212\n",
      "Node done: 62011CJ0210\n",
      "Node done: 62012CJ0124\n",
      "Node done: 62012CJ0099\n",
      "Node done: 62012CJ0319\n",
      "Node done: 62011CJ0397\n",
      "Node done: 62011CJ0073\n",
      "Node done: 62011CJ0630\n",
      "Node done: 62010CJ0383\n",
      "Node done: 62009CJ0529\n",
      "Degree done: 10\n",
      "Node done: 62011CJ0224\n",
      "Node done: 62011CJ0548\n",
      "Node done: 62011CJ0168\n",
      "Node done: 62012CJ0116\n",
      "Degree done: 15\n",
      "Node done: 62011CJ0350\n",
      "Node done: 62010CJ0584\n",
      "Degree done: 20\n",
      "Model done: logistic_regression\n"
     ]
    }
   ],
   "source": [
    "test_year = 2013\n",
    "degrees = [5, 10, 15, 20]\n",
    "models = [(rfe_tree, 'single_tree'), (random_forest, 'random_forest'), (log_model, 'logistic_regression')]\n",
    "model_results = {}\n",
    "for model, name in models:\n",
    "    model_results[name] = {}\n",
    "    for degree in degrees:\n",
    "        res = {}\n",
    "        nodes = set(x for x,_ in test_data.loc[test_data['src_degree'] == degree, 'source'].index)\n",
    "        # assert len(nodes) == len([n for n, d in  slice_graph_by_year(test_year, test_year, GCC) if len(GCC[n]) == degree])\n",
    "        for node in nodes:\n",
    "            res[node] = {}\n",
    "            # If there already exists predictions for this node at this degree, load them\n",
    "            if isfile('pickles/{}_{}_{}.pkl'.format(name, node, degree)):\n",
    "                res[node] = pkl.load(open('pickles/{}_{}_{}.pkl'.format(name, node, degree), 'rb'))\n",
    "            else:\n",
    "                # If the features of the node at this degree has been created, load them\n",
    "                if isfile('pickles/{}_validation_deg_{}.pkl'.format(node, degree)):\n",
    "                    panel = pd.read_pickle('pickles/{}_validation_deg_{}.pkl'.format(node, degree))\n",
    "                # Generate features\n",
    "                else:\n",
    "                    dict_to_df = {}\n",
    "                    e = GCC.edges(node, data=True)\n",
    "                    if not len(e) == degree:\n",
    "                        raise Exception(\"Mismatch: {}\".format(len(e)))\n",
    "                    GCC.remove_edges_from(e[1:degree-1])\n",
    "                    for i in range(1, degree):\n",
    "                        to_be_scored = [(node, y, {}) for y in set(GCC.nodes()) - set(node) \n",
    "                                        if not (node, y) in set((s,t) for s,t,_ in e[0:i])]\n",
    "                        data = get_features(GCC, to_be_scored, node+'_{}_edges'.format(i), False)\n",
    "                        nans = data.isnull().any(1).nonzero()[0]\n",
    "                        if len(nans)>0:\n",
    "                            print \"Nans in get features: {}\".format(nans)\n",
    "                        dict_to_df[i] = data\n",
    "                        GCC.add_edge(e[i][0], e[i][1])\n",
    "                    panel = pd.Panel(dict_to_df)\n",
    "                    panel.to_pickle('pickles/{}_validation_deg_{}.pkl'.format(node, degree))\n",
    "                # Perform predictions on generated or loaded features\n",
    "                for i, df in panel.iteritems():\n",
    "                    df.dropna()\n",
    "                    X = df.ix[:, [col for col in data.columns if col not in ['edge', 'source', 'target']]]\n",
    "                    probs = zip(df['edge'], [p[1] for p in model.predict_proba(X)])\n",
    "                    probs = sorted(probs, key=lambda x: x[1], reverse=True)\n",
    "                    res[node][i] = probs[0:degree - i]\n",
    "                with open('pickles/{}_{}_{}.pkl'.format(name, node, degree), 'wb') as fl:\n",
    "                    pkl.dump(res[node], fl)\n",
    "            print \"Node done: {}\".format(node)\n",
    "        model_results[name][degree]= res\n",
    "        print \"Degree done: {}\".format(degree)\n",
    "    print \"Model done: \" + name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1857.,   528.,   151.,    59.,    15.,    11.,     2.,     2.,\n",
       "            3.,     3.]),\n",
       " array([ 0.        ,  0.31922469,  0.63844938,  0.95767407,  1.27689876,\n",
       "         1.59612345,  1.91534814,  2.23457283,  2.55379752,  2.87302221,\n",
       "         3.1922469 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEACAYAAAC+gnFaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2fc076da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(X_train.loc[y_train, 'triadic_closeness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  2.99756700e+06,   3.17000000e+02,   2.00000000e+01,\n",
       "          2.00000000e+00,   1.10000000e+01,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          2.00000000e+00]),\n",
       " array([ 0.        ,  0.61547316,  1.23094632,  1.84641948,  2.46189264,\n",
       "         3.0773658 ,  3.69283896,  4.30831212,  4.92378528,  5.53925844,\n",
       "         6.1547316 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEACAYAAAByG0uxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ0SS1M0QkSR1M0QkSd0MEUlSt/8PKay1c6KQXmYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4349ff160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(X_train.loc[y_train==False, 'triadic_closeness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.values==True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.ix[:, [col for col in data.columns if col not in ['edge', 'source', 'target']]] \n",
    "y = data['edge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_tree.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "for i, edge in enumerate(e2[1:]):\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1 if y in GCC[node] else 0 for _,y,__ in to_be_scored])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('62009CJ0529', '62009CJ0529', {'score': 0.6687631067426463}),\n",
       " ('62009CJ0529', '62005CJ0232', {'score': 0.4021473695386738}),\n",
       " ('62009CJ0529', '62005CJ0207', {'score': 0.35214736953867387}),\n",
       " ('62009CJ0529', '62009CJ0304', {'score': 0.34676434676434675}),\n",
       " ('62009CJ0529', '62009CJ0549', {'score': 0.30311355311355315}),\n",
       " ('62009CJ0529', '62003CJ0415', {'score': 0.2570636950432347}),\n",
       " ('62009CJ0529', '61993CJ0348', {'score': 0.25331189129143095}),\n",
       " ('62009CJ0529', '62006CJ0419', {'score': 0.22373036170990132}),\n",
       " ('62009CJ0529', '62009CJ0303', {'score': 0.21978021978021978}),\n",
       " ('62009CJ0529', '62009CJ0305', {'score': 0.2039072039072039}),\n",
       " ('62009CJ0529', '62000CJ0404', {'score': 0.19824016563146996}),\n",
       " ('62009CJ0529', '62006CJ0441', {'score': 0.18563512361466325}),\n",
       " ('62009CJ0529', '62005CJ0280', {'score': 0.17243867243867245}),\n",
       " ('62009CJ0529', '62009CJ0454', {'score': 0.17226613965744403}),\n",
       " ('62009CJ0529', '62007CJ0369', {'score': 0.1598336304218657}),\n",
       " ('62009CJ0529', '62002CJ0099', {'score': 0.14903381642512076}),\n",
       " ('62009CJ0529', '61987CJ0142', {'score': 0.13761140819964351}),\n",
       " ('62009CJ0529', '62009CJ0352', {'score': 0.13636363636363635}),\n",
       " ('62009CJ0529', '62006CJ0039', {'score': 0.13025210084033612}),\n",
       " ('62009CJ0529', '61984CJ0052', {'score': 0.12878787878787878}),\n",
       " ('62009CJ0529', '61995CJ0280', {'score': 0.12681159420289856}),\n",
       " ('62009CJ0529', '62012CJ0353', {'score': 0.12237762237762238}),\n",
       " ('62009CJ0529', '62012CJ0344', {'score': 0.11025641025641025}),\n",
       " ('62009CJ0529', '62006CJ0177', {'score': 0.11025641025641025}),\n",
       " ('62009CJ0529', '62012CJ0411', {'score': 0.11025641025641025}),\n",
       " ('62009CJ0529', '62007CJ0214', {'score': 0.11025641025641025}),\n",
       " ('62009CJ0529', '62000CJ0209', {'score': 0.11025641025641025}),\n",
       " ('62009CJ0529', '62011CJ0576', {'score': 0.10101010101010101}),\n",
       " ('62009CJ0529', '62011CJ0533', {'score': 0.10101010101010101}),\n",
       " ('62009CJ0529', '62011CJ0374', {'score': 0.10101010101010101}),\n",
       " ('62009CJ0529', '62002CJ0304', {'score': 0.10101010101010101}),\n",
       " ('62009CJ0529', '61995CJ0024', {'score': 0.09903381642512077}),\n",
       " ('62009CJ0529', '61987CJ0094', {'score': 0.09347826086956522}),\n",
       " ('62009CJ0529', '61999CJ0261', {'score': 0.09347826086956522}),\n",
       " ('62009CJ0529', '61998CJ0471', {'score': 0.09090909090909091}),\n",
       " ('62009CJ0529', '62004CJ0234', {'score': 0.09090909090909091}),\n",
       " ('62009CJ0529', '62010CJ0221', {'score': 0.09090909090909091}),\n",
       " ('62009CJ0529', '62009CJ0351', {'score': 0.09090909090909091}),\n",
       " ('62009CJ0529', '62012CJ0095', {'score': 0.09090909090909091}),\n",
       " ('62009CJ0529', '62005CJ0462', {'score': 0.09090909090909091}),\n",
       " ('62009CJ0529', '62001CJ0224', {'score': 0.09090909090909091}),\n",
       " ('62009CJ0529', '62008CJ0002', {'score': 0.09090909090909091}),\n",
       " ('62009CJ0529', '62000CJ0277', {'score': 0.0787878787878788}),\n",
       " ('62009CJ0529', '61997CJ0075', {'score': 0.07681159420289854}),\n",
       " ('62009CJ0529', '62003CJ0485', {'score': 0.07681159420289854}),\n",
       " ('62009CJ0529', '61991CJ0183', {'score': 0.07681159420289854}),\n",
       " ('62009CJ0529', '61997CJ0404', {'score': 0.07681159420289854}),\n",
       " ('62009CJ0529', '62009CJ0302', {'score': 0.07142857142857142}),\n",
       " ('62009CJ0529', '61988CJ0143', {'score': 0.07142857142857142}),\n",
       " ('62009CJ0529', '61993CJ0465', {'score': 0.07142857142857142}),\n",
       " ('62009CJ0529', '62009CJ0471', {'score': 0.07142857142857142}),\n",
       " ('62009CJ0529', '62009CJ0071', {'score': 0.07142857142857142}),\n",
       " ('62009CJ0529', '61991CJ0072', {'score': 0.058823529411764705}),\n",
       " ('62009CJ0529', '62013CJ0069', {'score': 0.058823529411764705}),\n",
       " ('62009CJ0529', '62001CJ0005', {'score': 0.058823529411764705}),\n",
       " ('62009CJ0529', '61997CJ0200', {'score': 0.058823529411764705}),\n",
       " ('62009CJ0529', '62010CJ0081', {'score': 0.058823529411764705}),\n",
       " ('62009CJ0529', '62010CJ0403', {'score': 0.058823529411764705}),\n",
       " ('62009CJ0529', '61973CJ0173', {'score': 0.058823529411764705}),\n",
       " ('62009CJ0529', '61987CJ0102', {'score': 0.058823529411764705}),\n",
       " ('62009CJ0529', '61994CJ0241', {'score': 0.058823529411764705}),\n",
       " ('62009CJ0529', '62001CJ0278', {'score': 0.05555555555555555}),\n",
       " ('62009CJ0529', '62007CJ0568', {'score': 0.05555555555555555}),\n",
       " ('62009CJ0529', '62009CJ0407', {'score': 0.05555555555555555}),\n",
       " ('62009CJ0529', '62012CJ0055', {'score': 0.05555555555555555}),\n",
       " ('62009CJ0529', '62007CJ0121', {'score': 0.05555555555555555}),\n",
       " ('62009CJ0529', '62003CJ0377', {'score': 0.05}),\n",
       " ('62009CJ0529', '62002CJ0105', {'score': 0.05}),\n",
       " ('62009CJ0529', '62010CJ0017', {'score': 0.045454545454545456}),\n",
       " ('62009CJ0529', '62011CJ0270', {'score': 0.045454545454545456}),\n",
       " ('62009CJ0529', '62011CJ0279', {'score': 0.045454545454545456}),\n",
       " ('62009CJ0529', '62006CJ0070', {'score': 0.045454545454545456}),\n",
       " ('62009CJ0529', '62004CJ0177', {'score': 0.045454545454545456}),\n",
       " ('62009CJ0529', '62009CJ0201', {'score': 0.045454545454545456}),\n",
       " ('62009CJ0529', '62008CJ0334', {'score': 0.045454545454545456}),\n",
       " ('62009CJ0529', '62011CJ0241', {'score': 0.045454545454545456}),\n",
       " ('62009CJ0529', '61997CJ0387', {'score': 0.045454545454545456}),\n",
       " ('62009CJ0529', '62002CJ0087', {'score': 0.045454545454545456}),\n",
       " ('62009CJ0529', '61987CJ0301', {'score': 0.043478260869565216}),\n",
       " ('62009CJ0529', '62003CJ0456', {'score': 0.043478260869565216}),\n",
       " ('62009CJ0529', '61999CJ0058', {'score': 0.043478260869565216}),\n",
       " ('62009CJ0529', '62008CJ0507', {'score': 0.03333333333333333}),\n",
       " ('62009CJ0529', '62009CJ0210', {'score': 0.03333333333333333}),\n",
       " ('62009CJ0529', '61993CJ0350', {'score': 0.03333333333333333}),\n",
       " ('62009CJ0529', '61995CJ0265', {'score': 0.03333333333333333}),\n",
       " ('62009CJ0529', '62011CJ0613', {'score': 0.03333333333333333}),\n",
       " ('62009CJ0529', '62010CJ0243', {'score': 0.03333333333333333}),\n",
       " ('62009CJ0529', '61995CJ0052', {'score': 0.03333333333333333}),\n",
       " ('62009CJ0529', '62002CJ0230', {'score': 0}),\n",
       " ('62009CJ0529', '62002CJ0233', {'score': 0}),\n",
       " ('62009CJ0529', '62002CJ0234', {'score': 0}),\n",
       " ('62009CJ0529', '62002CJ0237', {'score': 0}),\n",
       " ('62009CJ0529', '62002CJ0236', {'score': 0}),\n",
       " ('62009CJ0529', '61960CJ0006', {'score': 0}),\n",
       " ('62009CJ0529', '62002CJ0238', {'score': 0}),\n",
       " ('62009CJ0529', '61960CJ0005', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0223', {'score': 0}),\n",
       " ('62009CJ0529', '61960CJ0001', {'score': 0}),\n",
       " ('62009CJ0529', '61995CJ0292', {'score': 0}),\n",
       " ('62009CJ0529', '61995CJ0297', {'score': 0}),\n",
       " ('62009CJ0529', '61995CJ0296', {'score': 0}),\n",
       " ('62009CJ0529', '61995CJ0295', {'score': 0}),\n",
       " ('62009CJ0529', '61995CJ0294', {'score': 0}),\n",
       " ('62009CJ0529', '61983CJ0274', {'score': 0}),\n",
       " ('62009CJ0529', '61983CJ0275', {'score': 0}),\n",
       " ('62009CJ0529', '61995CJ0299', {'score': 0}),\n",
       " ('62009CJ0529', '61995CJ0298', {'score': 0}),\n",
       " ('62009CJ0529', '61983CJ0270', {'score': 0}),\n",
       " ('62009CJ0529', '61983CJ0271', {'score': 0}),\n",
       " ('62009CJ0529', '61983CJ0272', {'score': 0}),\n",
       " ('62009CJ0529', '61983CJ0273', {'score': 0}),\n",
       " ('62009CJ0529', '61960CJ0009', {'score': 0}),\n",
       " ('62009CJ0529', '62002CJ0239', {'score': 0}),\n",
       " ('62009CJ0529', '62012CJ0508', {'score': 0}),\n",
       " ('62009CJ0529', '62012CJ0509', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0228', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0103', {'score': 0}),\n",
       " ('62009CJ0529', '61980CJ0152', {'score': 0}),\n",
       " ('62009CJ0529', '61980CJ0153', {'score': 0}),\n",
       " ('62009CJ0529', '61980CJ0150', {'score': 0}),\n",
       " ('62009CJ0529', '61980CJ0151', {'score': 0}),\n",
       " ('62009CJ0529', '61980CJ0156', {'score': 0}),\n",
       " ('62009CJ0529', '61980CJ0157', {'score': 0}),\n",
       " ('62009CJ0529', '61980CJ0154', {'score': 0}),\n",
       " ('62009CJ0529', '61980CJ0155', {'score': 0}),\n",
       " ('62009CJ0529', '61980CJ0158', {'score': 0}),\n",
       " ('62009CJ0529', '62002CJ0295', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0273', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0274', {'score': 0}),\n",
       " ('62009CJ0529', '61983CJ0278', {'score': 0}),\n",
       " ('62009CJ0529', '61983CJ0279', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0137', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0133', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0132', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0138', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0159', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0158', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0401', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0400', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0151', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0157', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0404', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0154', {'score': 0}),\n",
       " ('62009CJ0529', '61983CJ0277', {'score': 0}),\n",
       " ('62009CJ0529', '61991CJ0250', {'score': 0}),\n",
       " ('62009CJ0529', '61986CJ0188', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0261', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0265', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0264', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0266', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0268', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0018', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0019', {'score': 0}),\n",
       " ('62009CJ0529', '61993CJ0485', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0010', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0601', {'score': 0}),\n",
       " ('62009CJ0529', '61962CJ0002', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0604', {'score': 0}),\n",
       " ('62009CJ0529', '61962CJ0005', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0607', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0445', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0444', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0195', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0446', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0441', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0440', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0191', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0442', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0199', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0198', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0199', {'score': 0}),\n",
       " ('62009CJ0529', '61977CJ0044', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0192', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0190', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0191', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0197', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0195', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0229', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0228', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0368', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0221', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0362', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0361', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0222', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0226', {'score': 0}),\n",
       " ('62009CJ0529', '61999CJ0297', {'score': 0}),\n",
       " ('62009CJ0529', '61999CJ0294', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0219', {'score': 0}),\n",
       " ('62009CJ0529', '61999CJ0292', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0215', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0214', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0211', {'score': 0}),\n",
       " ('62009CJ0529', '61999CJ0299', {'score': 0}),\n",
       " ('62009CJ0529', '61999CJ0298', {'score': 0}),\n",
       " ('62009CJ0529', '61999CJ0091', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0083', {'score': 0}),\n",
       " ('62009CJ0529', '61982CJ0078', {'score': 0}),\n",
       " ('62009CJ0529', '61992CJ0303', {'score': 0}),\n",
       " ('62009CJ0529', '61976CJ0028', {'score': 0}),\n",
       " ('62009CJ0529', '61992CJ0304', {'score': 0}),\n",
       " ('62009CJ0529', '61999CJ0120', {'score': 0}),\n",
       " ('62009CJ0529', '61999CJ0123', {'score': 0}),\n",
       " ('62009CJ0529', '61999CJ0122', {'score': 0}),\n",
       " ('62009CJ0529', '61991CJ0003', {'score': 0}),\n",
       " ('62009CJ0529', '61999CJ0124', {'score': 0}),\n",
       " ('62009CJ0529', '61999CJ0127', {'score': 0}),\n",
       " ('62009CJ0529', '61999CJ0126', {'score': 0}),\n",
       " ('62009CJ0529', '62012CJ0234', {'score': 0}),\n",
       " ('62009CJ0529', '61988CJ0265', {'score': 0}),\n",
       " ('62009CJ0529', '61988CJ0267', {'score': 0}),\n",
       " ('62009CJ0529', '61988CJ0262', {'score': 0}),\n",
       " ('62009CJ0529', '61988CJ0263', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0398', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0392', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0394', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0395', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0396', {'score': 0}),\n",
       " ('62009CJ0529', '61978CJ0209', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0078', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0079', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0072', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0070', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0074', {'score': 0}),\n",
       " ('62009CJ0529', '61979CJ0025', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0237', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0234', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0232', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0233', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0230', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0231', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0206', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0204', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0203', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0201', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0200', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0384', {'score': 0}),\n",
       " ('62009CJ0529', '62004CJ0029', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0253', {'score': 0}),\n",
       " ('62009CJ0529', '62012CJ0249', {'score': 0}),\n",
       " ('62009CJ0529', '62012CJ0247', {'score': 0}),\n",
       " ('62009CJ0529', '62012CJ0246', {'score': 0}),\n",
       " ('62009CJ0529', '62012CJ0244', {'score': 0}),\n",
       " ('62009CJ0529', '62012CJ0241', {'score': 0}),\n",
       " ('62009CJ0529', '61986CJ0014', {'score': 0}),\n",
       " ('62009CJ0529', '61986CJ0010', {'score': 0}),\n",
       " ('62009CJ0529', '61986CJ0012', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0573', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0572', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0570', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0186', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0187', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0185', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0578', {'score': 0}),\n",
       " ('62009CJ0529', '62004CJ0200', {'score': 0}),\n",
       " ('62009CJ0529', '62002CJ0008', {'score': 0}),\n",
       " ('62009CJ0529', '62002CJ0009', {'score': 0}),\n",
       " ('62009CJ0529', '61991CJ0226', {'score': 0}),\n",
       " ('62009CJ0529', '62002CJ0004', {'score': 0}),\n",
       " ('62009CJ0529', '61991CJ0225', {'score': 0}),\n",
       " ('62009CJ0529', '61991CJ0222', {'score': 0}),\n",
       " ('62009CJ0529', '61991CJ0220', {'score': 0}),\n",
       " ('62009CJ0529', '62002CJ0001', {'score': 0}),\n",
       " ('62009CJ0529', '61983CJ0029', {'score': 0}),\n",
       " ('62009CJ0529', '61983CJ0028', {'score': 0}),\n",
       " ('62009CJ0529', '61983CJ0023', {'score': 0}),\n",
       " ('62009CJ0529', '61983CJ0024', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0098', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0099', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0092', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0093', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0090', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0097', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0108', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0053', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0050', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0051', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0102', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0103', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0101', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0106', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0059', {'score': 0}),\n",
       " ('62009CJ0529', '61995CJ0124', {'score': 0}),\n",
       " ('62009CJ0529', '61995CJ0127', {'score': 0}),\n",
       " ('62009CJ0529', '61995CJ0126', {'score': 0}),\n",
       " ('62009CJ0529', '61995CJ0121', {'score': 0}),\n",
       " ('62009CJ0529', '61995CJ0120', {'score': 0}),\n",
       " ('62009CJ0529', '61995CJ0122', {'score': 0}),\n",
       " ('62009CJ0529', '61995CJ0128', {'score': 0}),\n",
       " ('62009CJ0529', '61998CJ0478', {'score': 0}),\n",
       " ('62009CJ0529', '61998CJ0476', {'score': 0}),\n",
       " ('62009CJ0529', '61998CJ0477', {'score': 0}),\n",
       " ('62009CJ0529', '61998CJ0475', {'score': 0}),\n",
       " ('62009CJ0529', '61998CJ0472', {'score': 0}),\n",
       " ('62009CJ0529', '61998CJ0473', {'score': 0}),\n",
       " ('62009CJ0529', '61998CJ0470', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0082', {'score': 0}),\n",
       " ('62009CJ0529', '61989CJ0128', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0084', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0300', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0306', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0307', {'score': 0}),\n",
       " ('62009CJ0529', '61971CJ0032', {'score': 0}),\n",
       " ('62009CJ0529', '61971CJ0037', {'score': 0}),\n",
       " ('62009CJ0529', '61971CJ0036', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0050', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0051', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0052', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0053', {'score': 0}),\n",
       " ('62009CJ0529', '61979CJ0532', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0058', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0108', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0153', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0100', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0101', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0103', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0104', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0403', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0106', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0208', {'score': 0}),\n",
       " ('62009CJ0529', '62002CJ0014', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0299', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0298', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0028', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0029', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0022', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0293', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0021', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0295', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0294', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0296', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0274', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0275', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0276', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0277', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0270', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0271', {'score': 0}),\n",
       " ('62009CJ0529', '61961CJ0019', {'score': 0}),\n",
       " ('62009CJ0529', '61961CJ0014', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0328', {'score': 0}),\n",
       " ('62009CJ0529', '61961CJ0016', {'score': 0}),\n",
       " ('62009CJ0529', '61961CJ0017', {'score': 0}),\n",
       " ('62009CJ0529', '61961CJ0010', {'score': 0}),\n",
       " ('62009CJ0529', '61961CJ0013', {'score': 0}),\n",
       " ('62009CJ0529', '61999CJ0354', {'score': 0}),\n",
       " ('62009CJ0529', '61981CJ0103', {'score': 0}),\n",
       " ('62009CJ0529', '61981CJ0104', {'score': 0}),\n",
       " ('62009CJ0529', '61999CJ0353', {'score': 0}),\n",
       " ('62009CJ0529', '61999CJ0350', {'score': 0}),\n",
       " ('62009CJ0529', '61981CJ0108', {'score': 0}),\n",
       " ('62009CJ0529', '61981CJ0109', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0076', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0071', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0073', {'score': 0}),\n",
       " ('62009CJ0529', '61994CJ0209', {'score': 0}),\n",
       " ('62009CJ0529', '61994CJ0201', {'score': 0}),\n",
       " ('62009CJ0529', '61994CJ0205', {'score': 0}),\n",
       " ('62009CJ0529', '61994CJ0206', {'score': 0}),\n",
       " ('62009CJ0529', '61982CJ0172', {'score': 0}),\n",
       " ('62009CJ0529', '61982CJ0173', {'score': 0}),\n",
       " ('62009CJ0529', '61982CJ0171', {'score': 0}),\n",
       " ('62009CJ0529', '61982CJ0177', {'score': 0}),\n",
       " ('62009CJ0529', '61982CJ0174', {'score': 0}),\n",
       " ('62009CJ0529', '61982CJ0175', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0364', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0144', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0495', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0589', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0141', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0140', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0143', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0142', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0583', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0581', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0586', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0587', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0584', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0585', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0108', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0104', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0107', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0106', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0103', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0102', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0417', {'score': 0}),\n",
       " ('62009CJ0529', '61983CJ0254', {'score': 0}),\n",
       " ('62009CJ0529', '61983CJ0255', {'score': 0}),\n",
       " ('62009CJ0529', '61983CJ0252', {'score': 0}),\n",
       " ('62009CJ0529', '61983CJ0253', {'score': 0}),\n",
       " ('62009CJ0529', '61983CJ0250', {'score': 0}),\n",
       " ('62009CJ0529', '61983CJ0251', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0172', {'score': 0}),\n",
       " ('62009CJ0529', '61983CJ0258', {'score': 0}),\n",
       " ('62009CJ0529', '61998CJ0110', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0174', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0537', {'score': 0}),\n",
       " ('62009CJ0529', '62012CJ0522', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0411', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0321', {'score': 0}),\n",
       " ('62009CJ0529', '61980CJ0137', {'score': 0}),\n",
       " ('62009CJ0529', '61980CJ0130', {'score': 0}),\n",
       " ('62009CJ0529', '61980CJ0132', {'score': 0}),\n",
       " ('62009CJ0529', '61980CJ0139', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0399', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0391', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0390', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0392', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0395', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0394', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0397', {'score': 0}),\n",
       " ('62009CJ0529', '61988CJ0024', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0326', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0177', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0176', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0171', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0170', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0173', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0172', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0434', {'score': 0}),\n",
       " ('62009CJ0529', '62012CJ0383', {'score': 0}),\n",
       " ('62009CJ0529', '62012CJ0386', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0432', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0433', {'score': 0}),\n",
       " ('62009CJ0529', '62012CJ0388', {'score': 0}),\n",
       " ('62009CJ0529', '61972CJ0048', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0115', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0388', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0389', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0380', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0382', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0383', {'score': 0}),\n",
       " ('62009CJ0529', '61999CJ0206', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0386', {'score': 0}),\n",
       " ('62009CJ0529', '61965CJ0010', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0503', {'score': 0}),\n",
       " ('62009CJ0529', '61990CJ0179', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0159', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0158', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0157', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0156', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0155', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0154', {'score': 0}),\n",
       " ('62009CJ0529', '61990CJ0177', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0152', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0151', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0507', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0032', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0033', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0030', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0031', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0037', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0035', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0038', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0622', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0623', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0621', {'score': 0}),\n",
       " ('62009CJ0529', '61962CJ0026', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0429', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0625', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0427', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0426', {'score': 0}),\n",
       " ('62009CJ0529', '61962CJ0028', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0424', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0423', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0422', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0421', {'score': 0}),\n",
       " ('62009CJ0529', '61977CJ0022', {'score': 0}),\n",
       " ('62009CJ0529', '61977CJ0023', {'score': 0}),\n",
       " ('62009CJ0529', '61977CJ0028', {'score': 0}),\n",
       " ('62009CJ0529', '61977CJ0029', {'score': 0}),\n",
       " ('62009CJ0529', '61991CJ0152', {'score': 0}),\n",
       " ('62009CJ0529', '61991CJ0153', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0349', {'score': 0}),\n",
       " ('62009CJ0529', '61991CJ0155', {'score': 0}),\n",
       " ('62009CJ0529', '61991CJ0156', {'score': 0}),\n",
       " ('62009CJ0529', '61991CJ0157', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0345', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0344', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0347', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0346', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0341', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0340', {'score': 0}),\n",
       " ('62009CJ0529', '61999CJ0023', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0277', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0275', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0274', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0273', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0272', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0271', {'score': 0}),\n",
       " ('62009CJ0529', '62004CJ0273', {'score': 0}),\n",
       " ('62009CJ0529', '62004CJ0275', {'score': 0}),\n",
       " ('62009CJ0529', '62004CJ0274', {'score': 0}),\n",
       " ('62009CJ0529', '62004CJ0525', {'score': 0}),\n",
       " ('62009CJ0529', '61992CJ0364', {'score': 0}),\n",
       " ('62009CJ0529', '61992CJ0365', {'score': 0}),\n",
       " ('62009CJ0529', '61992CJ0360', {'score': 0}),\n",
       " ('62009CJ0529', '61981CJ0314', {'score': 0}),\n",
       " ('62009CJ0529', '61981CJ0311', {'score': 0}),\n",
       " ('62009CJ0529', '61981CJ0310', {'score': 0}),\n",
       " ('62009CJ0529', '61988CJ0246', {'score': 0}),\n",
       " ('62009CJ0529', '61988CJ0244', {'score': 0}),\n",
       " ('62009CJ0529', '61988CJ0245', {'score': 0}),\n",
       " ('62009CJ0529', '61988CJ0248', {'score': 0}),\n",
       " ('62009CJ0529', '61988CJ0249', {'score': 0}),\n",
       " ('62009CJ0529', '61976CJ0087', {'score': 0}),\n",
       " ('62009CJ0529', '61993CJ0153', {'score': 0}),\n",
       " ('62009CJ0529', '61976CJ0085', {'score': 0}),\n",
       " ('62009CJ0529', '61993CJ0151', {'score': 0}),\n",
       " ('62009CJ0529', '61976CJ0083', {'score': 0}),\n",
       " ('62009CJ0529', '61993CJ0154', {'score': 0}),\n",
       " ('62009CJ0529', '61976CJ0080', {'score': 0}),\n",
       " ('62009CJ0529', '61976CJ0089', {'score': 0}),\n",
       " ('62009CJ0529', '61976CJ0088', {'score': 0}),\n",
       " ('62009CJ0529', '61974CJ0041', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0098', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0015', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0016', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0017', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0012', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0013', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0221', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0223', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0225', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0227', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0226', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0085', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0087', {'score': 0}),\n",
       " ('62009CJ0529', '62012CJ0262', {'score': 0}),\n",
       " ('62009CJ0529', '62012CJ0265', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0080', {'score': 0}),\n",
       " ('62009CJ0529', '62012CJ0267', {'score': 0}),\n",
       " ('62009CJ0529', '62012CJ0269', {'score': 0}),\n",
       " ('62009CJ0529', '61963CJ0083', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0089', {'score': 0}),\n",
       " ('62009CJ0529', '61986CJ0077', {'score': 0}),\n",
       " ('62009CJ0529', '61986CJ0076', {'score': 0}),\n",
       " ('62009CJ0529', '61986CJ0074', {'score': 0}),\n",
       " ('62009CJ0529', '61986CJ0070', {'score': 0}),\n",
       " ('62009CJ0529', '61990CJ0343', {'score': 0}),\n",
       " ('62009CJ0529', '61990CJ0344', {'score': 0}),\n",
       " ('62009CJ0529', '61990CJ0345', {'score': 0}),\n",
       " ('62009CJ0529', '61990CJ0346', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0196', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0555', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0554', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0556', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0447', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0553', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0552', {'score': 0}),\n",
       " ('62009CJ0529', '61979CJ0804', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0194', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0193', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0192', {'score': 0}),\n",
       " ('62009CJ0529', '62002CJ0284', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0443', {'score': 0}),\n",
       " ('62009CJ0529', '61986CJ0124', {'score': 0}),\n",
       " ('62009CJ0529', '62002CJ0286', {'score': 0}),\n",
       " ('62009CJ0529', '61986CJ0126', {'score': 0}),\n",
       " ('62009CJ0529', '62002CJ0280', {'score': 0}),\n",
       " ('62009CJ0529', '61979CJ0803', {'score': 0}),\n",
       " ('62009CJ0529', '62002CJ0281', {'score': 0}),\n",
       " ('62009CJ0529', '61989CJ0328', {'score': 0}),\n",
       " ('62009CJ0529', '62002CJ0288', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0446', {'score': 0}),\n",
       " ('62009CJ0529', '61967CJ0019', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0169', {'score': 0}),\n",
       " ('62009CJ0529', '61995CJ0147', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0165', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0166', {'score': 0}),\n",
       " ('62009CJ0529', '61995CJ0144', {'score': 0}),\n",
       " ('62009CJ0529', '61995CJ0143', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0161', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0162', {'score': 0}),\n",
       " ('62009CJ0529', '61958CJ0042', {'score': 0}),\n",
       " ('62009CJ0529', '61979CJ0004', {'score': 0}),\n",
       " ('62009CJ0529', '62002CJ0078', {'score': 0}),\n",
       " ('62009CJ0529', '62004CJ0040', {'score': 0}),\n",
       " ('62009CJ0529', '62004CJ0517', {'score': 0}),\n",
       " ('62009CJ0529', '62004CJ0042', {'score': 0}),\n",
       " ('62009CJ0529', '61967CJ0011', {'score': 0}),\n",
       " ('62009CJ0529', '62004CJ0513', {'score': 0}),\n",
       " ('62009CJ0529', '62004CJ0046', {'score': 0}),\n",
       " ('62009CJ0529', '62004CJ0518', {'score': 0}),\n",
       " ('62009CJ0529', '62004CJ0519', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0367', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0360', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0362', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0363', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0368', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0369', {'score': 0}),\n",
       " ('62009CJ0529', '61990CJ0295(01)', {'score': 0}),\n",
       " ('62009CJ0529', '61977CJ0041', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0122', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0121', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0126', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0125', {'score': 0}),\n",
       " ('62009CJ0529', '61993CJ0417', {'score': 0}),\n",
       " ('62009CJ0529', '61979CJ0799(01)', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0059', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0271', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0270', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0277', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0276', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0275', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0044', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0045', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0279', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0278', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0040', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0041', {'score': 0}),\n",
       " ('62009CJ0529', '61993CJ0412', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0508', {'score': 0}),\n",
       " ('62009CJ0529', '61981CJ0129', {'score': 0}),\n",
       " ('62009CJ0529', '61981CJ0126', {'score': 0}),\n",
       " ('62009CJ0529', '61981CJ0124', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0017', {'score': 0}),\n",
       " ('62009CJ0529', '61979CJ0049', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0078', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0079', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0013', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0012', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0011', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0220', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0072', {'score': 0}),\n",
       " ('62009CJ0529', '61979CJ0041', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0070', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0071', {'score': 0}),\n",
       " ('62009CJ0529', '61979CJ0044', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0019', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0018', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0360', {'score': 0}),\n",
       " ('62009CJ0529', '61982CJ0118', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0315', {'score': 0}),\n",
       " ('62009CJ0529', '61982CJ0116', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0364', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0129', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0127', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0123', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0121', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0342', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0340', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0347', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0346', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0259', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0256', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0257', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0349', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0348', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0252', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0250', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0346', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0347', {'score': 0}),\n",
       " ('62009CJ0529', '61995CJ0360', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0344', {'score': 0}),\n",
       " ('62009CJ0529', '61988CJ0188', {'score': 0}),\n",
       " ('62009CJ0529', '61988CJ0181', {'score': 0}),\n",
       " ('62009CJ0529', '61988CJ0180', {'score': 0}),\n",
       " ('62009CJ0529', '61988CJ0186', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0167', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0166', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0164', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0162', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0161', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0358', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0498', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0353', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0495', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0350', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0491', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0492', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0493', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0591', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0391', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0472', {'score': 0}),\n",
       " ('62009CJ0529', '61989CJ0010', {'score': 0}),\n",
       " ('62009CJ0529', '61989CJ0011', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0372', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0370', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0377', {'score': 0}),\n",
       " ('62009CJ0529', '61998CJ0399', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0374', {'score': 0}),\n",
       " ('62009CJ0529', '61998CJ0397', {'score': 0}),\n",
       " ('62009CJ0529', '61998CJ0396', {'score': 0}),\n",
       " ('62009CJ0529', '61998CJ0393', {'score': 0}),\n",
       " ('62009CJ0529', '61998CJ0390', {'score': 0}),\n",
       " ('62009CJ0529', '61974CJ0021', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0117', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0149', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0114', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0113', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0416', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0417', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0142', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0415', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0412', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0145', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0146', {'score': 0}),\n",
       " ('62009CJ0529', '61996CJ0118', {'score': 0}),\n",
       " ('62009CJ0529', '61993CJ0430', {'score': 0}),\n",
       " ('62009CJ0529', '61980CJ0116', {'score': 0}),\n",
       " ('62009CJ0529', '61980CJ0114', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0212', {'score': 0}),\n",
       " ('62009CJ0529', '61980CJ0112', {'score': 0}),\n",
       " ('62009CJ0529', '61980CJ0113', {'score': 0}),\n",
       " ('62009CJ0529', '61980CJ0111', {'score': 0}),\n",
       " ('62009CJ0529', '62012CJ0109', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0330', {'score': 0}),\n",
       " ('62009CJ0529', '62012CJ0100', {'score': 0}),\n",
       " ('62009CJ0529', '62012CJ0101', {'score': 0}),\n",
       " ('62009CJ0529', '62012CJ0104', {'score': 0}),\n",
       " ('62009CJ0529', '62012CJ0105', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0392', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0188', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0391', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0396', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0397', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0394', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0395', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0398', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0399', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0384', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0170', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0173', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0039', {'score': 0}),\n",
       " ('62009CJ0529', '61990CJ0159', {'score': 0}),\n",
       " ('62009CJ0529', '61990CJ0158', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0176', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0204', {'score': 0}),\n",
       " ('62009CJ0529', '61990CJ0157', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0205', {'score': 0}),\n",
       " ('62009CJ0529', '61982CJ0288', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0380', {'score': 0}),\n",
       " ('62009CJ0529', '61982CJ0284', {'score': 0}),\n",
       " ('62009CJ0529', '61982CJ0286', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0207', {'score': 0}),\n",
       " ('62009CJ0529', '61982CJ0281', {'score': 0}),\n",
       " ('62009CJ0529', '61982CJ0283', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0054', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0055', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0056', {'score': 0}),\n",
       " ('62009CJ0529', '62012CJ0309', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0050', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0051', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0053', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0058', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0401', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0645', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0646', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0150', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0405', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0404', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0642', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0643', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0409', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0648', {'score': 0}),\n",
       " ('62009CJ0529', '61995CJ0080', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0388', {'score': 0}),\n",
       " ('62009CJ0529', '61995CJ0084', {'score': 0}),\n",
       " ('62009CJ0529', '61995CJ0085', {'score': 0}),\n",
       " ('62009CJ0529', '61999CJ0345', {'score': 0}),\n",
       " ('62009CJ0529', '61995CJ0088', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0187', {'score': 0}),\n",
       " ('62009CJ0529', '61985CJ0124', {'score': 0}),\n",
       " ('62009CJ0529', '61977CJ0008', {'score': 0}),\n",
       " ('62009CJ0529', '61977CJ0009', {'score': 0}),\n",
       " ('62009CJ0529', '61977CJ0007', {'score': 0}),\n",
       " ('62009CJ0529', '61977CJ0005', {'score': 0}),\n",
       " ('62009CJ0529', '61977CJ0002', {'score': 0}),\n",
       " ('62009CJ0529', '61977CJ0001', {'score': 0}),\n",
       " ('62009CJ0529', '61999CJ0348', {'score': 0}),\n",
       " ('62009CJ0529', '61991CJ0172', {'score': 0}),\n",
       " ('62009CJ0529', '61991CJ0173', {'score': 0}),\n",
       " ('62009CJ0529', '61991CJ0171', {'score': 0}),\n",
       " ('62009CJ0529', '61991CJ0177', {'score': 0}),\n",
       " ('62009CJ0529', '61991CJ0174', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0327', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0324', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0321', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0320', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0329', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0328', {'score': 0}),\n",
       " ('62009CJ0529', '61999CJ0253', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0258', {'score': 0}),\n",
       " ('62009CJ0529', '61999CJ0257', {'score': 0}),\n",
       " ('62009CJ0529', '61999CJ0255', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0523', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0250', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0253', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0252', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0255', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0254', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0256', {'score': 0}),\n",
       " ('62009CJ0529', '62004CJ0259', {'score': 0}),\n",
       " ('62009CJ0529', '62004CJ0258', {'score': 0}),\n",
       " ('62009CJ0529', '62004CJ0255', {'score': 0}),\n",
       " ('62009CJ0529', '62004CJ0251', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0537', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0627', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0625', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0624', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0621', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0620', {'score': 0}),\n",
       " ('62009CJ0529', '61973CJ0127', {'score': 0}),\n",
       " ('62009CJ0529', '61973CJ0121', {'score': 0}),\n",
       " ('62009CJ0529', '61973CJ0120', {'score': 0}),\n",
       " ('62009CJ0529', '61973CJ0122', {'score': 0}),\n",
       " ('62009CJ0529', '61979CJ1252', {'score': 0}),\n",
       " ('62009CJ0529', '61979CJ1253', {'score': 0}),\n",
       " ('62009CJ0529', '61979CJ1251', {'score': 0}),\n",
       " ('62009CJ0529', '61993CJ0135', {'score': 0}),\n",
       " ('62009CJ0529', '61993CJ0136', {'score': 0}),\n",
       " ('62009CJ0529', '61993CJ0130', {'score': 0}),\n",
       " ('62009CJ0529', '61993CJ0131', {'score': 0}),\n",
       " ('62009CJ0529', '61993CJ0132', {'score': 0}),\n",
       " ('62009CJ0529', '61993CJ0133', {'score': 0}),\n",
       " ('62009CJ0529', '61956CJ0010', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0036', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0037', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0032', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0033', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0031', {'score': 0}),\n",
       " ('62009CJ0529', '61992CJ0430', {'score': 0}),\n",
       " ('62009CJ0529', '61992CJ0431', {'score': 0}),\n",
       " ('62009CJ0529', '61992CJ0432', {'score': 0}),\n",
       " ('62009CJ0529', '61992CJ0345', {'score': 0}),\n",
       " ('62009CJ0529', '61992CJ0435', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0039', {'score': 0}),\n",
       " ('62009CJ0529', '61994CJ0018', {'score': 0}),\n",
       " ('62009CJ0529', '61994CJ0012', {'score': 0}),\n",
       " ('62009CJ0529', '61994CJ0013', {'score': 0}),\n",
       " ('62009CJ0529', '61994CJ0016', {'score': 0}),\n",
       " ('62009CJ0529', '61994CJ0017', {'score': 0}),\n",
       " ('62009CJ0529', '61975CJ0008', {'score': 0}),\n",
       " ('62009CJ0529', '61975CJ0009', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0293', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0290', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0291', {'score': 0}),\n",
       " ('62009CJ0529', '61975CJ0004', {'score': 0}),\n",
       " ('62009CJ0529', '61975CJ0007', {'score': 0}),\n",
       " ('62009CJ0529', '61963CJ0067', {'score': 0}),\n",
       " ('62009CJ0529', '61963CJ0066', {'score': 0}),\n",
       " ('62009CJ0529', '61986CJ0050', {'score': 0}),\n",
       " ('62009CJ0529', '61990CJ0369', {'score': 0}),\n",
       " ('62009CJ0529', '61986CJ0055', {'score': 0}),\n",
       " ('62009CJ0529', '61986CJ0057', {'score': 0}),\n",
       " ('62009CJ0529', '61986CJ0056', {'score': 0}),\n",
       " ('62009CJ0529', '61990CJ0362', {'score': 0}),\n",
       " ('62009CJ0529', '61986CJ0058', {'score': 0}),\n",
       " ('62009CJ0529', '61990CJ0360', {'score': 0}),\n",
       " ('62009CJ0529', '61990CJ0361', {'score': 0}),\n",
       " ('62009CJ0529', '61990CJ0364', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0537', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0536', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0535', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0534', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0533', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0531', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0530', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0539', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0538', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0308', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0520', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0090', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0092', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0095', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0097', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0096', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0098', {'score': 0}),\n",
       " ('62009CJ0529', '61990CJ0097', {'score': 0}),\n",
       " ('62009CJ0529', '61990CJ0090', {'score': 0}),\n",
       " ('62009CJ0529', '61990CJ0093', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0518', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0514', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0516', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0517', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0510', {'score': 0}),\n",
       " ('62009CJ0529', '62006CJ0511', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0147', {'score': 0}),\n",
       " ('62009CJ0529', '61995CJ0163', {'score': 0}),\n",
       " ('62009CJ0529', '61995CJ0165', {'score': 0}),\n",
       " ('62009CJ0529', '61995CJ0164', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0140', {'score': 0}),\n",
       " ('62009CJ0529', '62007CJ0141', {'score': 0}),\n",
       " ('62009CJ0529', '61995CJ0169', {'score': 0}),\n",
       " ('62009CJ0529', '61995CJ0168', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0281', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0280', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0284', {'score': 0}),\n",
       " ('62009CJ0529', '61987CJ0287', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0438', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0439', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0348', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0346', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0431', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0345', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0434', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0343', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0340', {'score': 0}),\n",
       " ('62009CJ0529', '62009CJ0437', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0320', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0322', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0323', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0324', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0497', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0494', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0495', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0329', {'score': 0}),\n",
       " ('62009CJ0529', '61989CJ0308', {'score': 0}),\n",
       " ('62009CJ0529', '61989CJ0309', {'score': 0}),\n",
       " ('62009CJ0529', '61989CJ0300', {'score': 0}),\n",
       " ('62009CJ0529', '61989CJ0306', {'score': 0}),\n",
       " ('62009CJ0529', '61989CJ0307', {'score': 0}),\n",
       " ('62009CJ0529', '61989CJ0304', {'score': 0}),\n",
       " ('62009CJ0529', '61989CJ0305', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0145', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0146', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0147', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0140', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0142', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0148', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0149', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0255', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0067', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0064', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0256', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0063', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0253', {'score': 0}),\n",
       " ('62009CJ0529', '61989CJ0169', {'score': 0}),\n",
       " ('62009CJ0529', '62004CJ0063', {'score': 0}),\n",
       " ('62009CJ0529', '61989CJ0162', {'score': 0}),\n",
       " ('62009CJ0529', '61989CJ0163', {'score': 0}),\n",
       " ('62009CJ0529', '62004CJ0064', {'score': 0}),\n",
       " ('62009CJ0529', '62004CJ0065', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0039', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0038', {'score': 0}),\n",
       " ('62009CJ0529', '62008CJ0089', {'score': 0}),\n",
       " ('62009CJ0529', '61981CJ0144', {'score': 0}),\n",
       " ('62009CJ0529', '61981CJ0145', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0033', {'score': 0}),\n",
       " ('62009CJ0529', '61981CJ0147', {'score': 0}),\n",
       " ('62009CJ0529', '61984CJ0034', {'score': 0}),\n",
       " ('62009CJ0529', '61979CJ0062', {'score': 0}),\n",
       " ('62009CJ0529', '61979CJ0061', {'score': 0}),\n",
       " ('62009CJ0529', '61979CJ0066', {'score': 0}),\n",
       " ('62009CJ0529', '61979CJ0067', {'score': 0}),\n",
       " ('62009CJ0529', '61979CJ0065', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0360', {'score': 0}),\n",
       " ('62009CJ0529', '62005CJ0361', {'score': 0}),\n",
       " ('62009CJ0529', '61979CJ0068', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0010', {'score': 0}),\n",
       " ('62009CJ0529', '62010CJ0011', {'score': 0}),\n",
       " ('62009CJ0529', '62004CJ0392', {'score': 0}),\n",
       " ('62009CJ0529', '62004CJ0393', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0353', {'score': 0}),\n",
       " ('62009CJ0529', '62002CJ0460', {'score': 0}),\n",
       " ('62009CJ0529', '61982CJ0136', {'score': 0}),\n",
       " ('62009CJ0529', '62001CJ0352', {'score': 0}),\n",
       " ('62009CJ0529', '61982CJ0132', {'score': 0}),\n",
       " ('62009CJ0529', '61982CJ0133', {'score': 0}),\n",
       " ('62009CJ0529', '61982CJ0139', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0453', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0452', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0103', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0450', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0457', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0104', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0107', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0109', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0108', {'score': 0}),\n",
       " ('62009CJ0529', '62000CJ0458', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0365', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0364', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0366', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0360', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0405', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0199', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0198', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0191', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0193', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0195', {'score': 0}),\n",
       " ('62009CJ0529', '62003CJ0197', {'score': 0}),\n",
       " ('62009CJ0529', '61999CJ0068', {'score': 0}),\n",
       " ('62009CJ0529', '61999CJ0069', {'score': 0}),\n",
       " ('62009CJ0529', '61999CJ0063', {'score': 0}),\n",
       " ('62009CJ0529', '61964CJ0045(01)', {'score': 0}),\n",
       " ('62009CJ0529', '61999CJ0066', {'score': 0}),\n",
       " ('62009CJ0529', '61999CJ0067', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0149', {'score': 0}),\n",
       " ('62009CJ0529', '61988CJ0161', {'score': 0}),\n",
       " ('62009CJ0529', '61988CJ0167', {'score': 0}),\n",
       " ('62009CJ0529', '61988CJ0165', {'score': 0}),\n",
       " ('62009CJ0529', '61988CJ0164', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0140', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0143', {'score': 0}),\n",
       " ('62009CJ0529', '61988CJ0168', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0145', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0144', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0147', {'score': 0}),\n",
       " ('62009CJ0529', '61997CJ0219', {'score': 0}),\n",
       " ('62009CJ0529', '62011CJ0108', {'score': 0}),\n",
       " ('62009CJ0529', '62002CJ0438', {'score': 0}),\n",
       " ...]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(to_be_scored, key=lambda x: x[2]['score'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'62009CJ0529' in GCC['62009CJ0529'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'61998CJ0378': {},\n",
       " '61998CJ0480': {},\n",
       " '61999CJ0499': {'date': datetime.date(2013, 1, 24)},\n",
       " '62008CJ0526': {},\n",
       " '62009CJ0331': {},\n",
       " '62009CJ0496': {},\n",
       " '62010CJ0243': {},\n",
       " '62010CJ0354': {},\n",
       " '62010CJ0485': {},\n",
       " '62010CJ0610': {}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " GCC['62009CJ0529']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'61998CJ0378': {'date': datetime.date(2013, 1, 24)},\n",
       " '61998CJ0480': {'date': datetime.date(2013, 1, 24)},\n",
       " '61999CJ0499': {'date': datetime.date(2013, 1, 24)},\n",
       " '62008CJ0526': {'date': datetime.date(2013, 1, 24)},\n",
       " '62009CJ0331': {'date': datetime.date(2013, 1, 24)},\n",
       " '62009CJ0496': {'date': datetime.date(2013, 1, 24)},\n",
       " '62010CJ0243': {'date': datetime.date(2013, 1, 24)},\n",
       " '62010CJ0354': {'date': datetime.date(2013, 1, 24)},\n",
       " '62010CJ0485': {'date': datetime.date(2013, 1, 24)},\n",
       " '62010CJ0610': {'date': datetime.date(2013, 1, 24)}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G['62009CJ0529']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "a = per_node_precision(GCC, model_results['logistic_regression'][10])\n",
    "b = per_node_precision(GCC, model_results['single_tree'][10])\n",
    "c = per_node_precision(GCC, model_results['random_forest'][10])\n",
    "d = {k: sum(p)/len(p) for k,p in a.iteritems() if len(p) != 0}\n",
    "e = {k: sum(p)/len(p) for k,p in b.iteritems() if len(p) != 0}\n",
    "f = {k: sum(p)/len(p) for k,p in c.iteritems() if len(p) != 0}\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(d.keys(), d.values(), e.keys(), e.values(), f.keys(), f.values(), lw=1.0, marker='o')\n",
    "plt.legend(['Logistic regression', 'Decision tree', 'Random forest'], markerscale=1, fontsize=20)\n",
    "plt.ylabel('Precision', fontsize=20)\n",
    "plt.xlabel('Number of edges on source node', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "srt = sorted(model_results['logistic_regression'][10]['62012CJ0344'], key=lambda x: x[2]['score'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_now = data['edge']\n",
    "prec = rfe_forest.predict(X)\n",
    "prob = [p[1] for p in rfe_forest.predict_proba(X)]\n",
    "z = zip(y_now, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ys, pr in zip(y_now, prec):\n",
    "    if ys == True:\n",
    "        print ys==pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted(z, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print classification_report(y_test, prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ps=[]\n",
    "for i, edge in enumerate(srt):\n",
    "    x = edge[0]\n",
    "    y = edge[1]\n",
    "    d = edge[2]\n",
    "    if y in GCC[x]:\n",
    "        ps.append(d['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_res2 = model_results\n",
    "for model, degree in model_results.iteritems():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_results['logistic_regression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def per_node_precision(G, results):\n",
    "    \"\"\"\n",
    "    results : dict\n",
    "        A dict of {node: [e1, e2, ... e_n]} where e is an edge of the form (source, target, {'n_edges': x, 'score': y}) where\n",
    "        n_edges number of edges the node had when the prediction was made.\n",
    "    \"\"\"\n",
    "    \n",
    "    m = 43\n",
    "    # Create a dict that all the edges sorted by score and grouped by n_edges and then node\n",
    "    s = {n: {k: [] for k in range(1,m+1)} for n in results.iterkeys()}\n",
    "    for node, node_res in results.iteritems():\n",
    "        # Sort the entire list of results\n",
    "        srt = sorted(node_res, key=lambda x: x[2]['score'], reverse=True)\n",
    "        for x,y,data in srt:\n",
    "            # Add each result to its proper bin\n",
    "            s[node][data['n_edges']].append((x,y,{'score': data['score']}))\n",
    "    precisions = {k: [] for k in range(1,m+1)}\n",
    "    edge_set = set(G.edges())\n",
    "    for node, node_res in s.iteritems():\n",
    "        n = G.out_degree(node)\n",
    "        for level, results in node_res.iteritems():\n",
    "            L = n-level\n",
    "            if len(results) == 0:\n",
    "                break\n",
    "            precisions[level].append(1.0*len([(edge[0],edge[1]) for edge in results[0:L] if (edge[0], edge[1]) in edge_set])/L)\n",
    "    return precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grps=it.groupby(model_results['logistic_regression'][10], lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(grps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,df in enumerate(pn.iteritems()):\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tt = slice_graph_by_year(2013, 2013, GCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len([n for n, d in tt if len(G[n]) == 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the accuracy of the logistic model seems incredibly good this simple evaluation hides an important issue which can be seen when looking at the per-class metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "preds = logi.predict(test_data[:,1:])\n",
    "print classification_report(test_data[:,0], preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The model is able to predict the non-existence of links very well, but completely fails to predict existing links which are exactly the cases that are interesting. This can be seen as having a model that will always predict that no link will form will have very nice accuracy due to the imbalance between classes. It is therefore necessary to train the model on an a more balanced dataset.\n",
    "\n",
    "[Link prediction in dynamic weighted and directed social networks] proposes a way to combat this. Since the set of potential edges, $D$, has the subsets of existing links, $D^+$ and non-existing links, $D^-$, where $D^- >> D^+$ it is possible to split into $m$ sub-sets each of size $|D^+|$, $S_i$ so that $\\sum_i S_i = D^-$.\n",
    "\n",
    "Models are then trained on $D^+ S_i \\ \\forall \\ i \\in m$  resulting in $m$ models all trained on the same positive cases. To perform classification of a potential link majority voting among the classifiers is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split the cases in positive and negative samples\n",
    "D_pos = train_data[train_data[:,0] == 1]\n",
    "D_neg = train_data[train_data[:,0] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute models for each case\n",
    "m = len(D_neg)/len(D_pos)\n",
    "try:\n",
    "    models = pkl.load(open('pickles/majority_logistic.pkl', 'rb'))\n",
    "except:\n",
    "    models = []\n",
    "    for i in range(0, m):\n",
    "        S = np.array(D_neg[i*len(D_pos):(i+1)*len(D_pos)])\n",
    "        model = LogisticRegression(C=1e5)\n",
    "        models.append(model.fit(np.append(S[:,1:], D_pos[:,1:], axis=0), np.append(S[:,0], D_pos[:,0], axis = 0)))\n",
    "    with open('pickles/majority_logistic.pkl', 'wb') as fl:\n",
    "        pkl.dump(models, fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Compute models for each case\n",
    "m = len(D_neg)/len(D_pos)\n",
    "try:\n",
    "    models = pkl.load(open('pickles/majority_svc.pkl', 'rb'))\n",
    "except:\n",
    "    models = []\n",
    "    for i in range(0, m):\n",
    "        S = np.array(D_neg[i*len(D_pos):(i+1)*len(D_pos)])\n",
    "        model = LinearSVC()\n",
    "        models.append(model.fit(np.append(S[:,1:], D_pos[:,1:], axis=0), np.append(S[:,0], D_pos[:,0], axis = 0)))\n",
    "    with open('pickles/majority_svc.pkl', 'wb') as fl:\n",
    "        pkl.dump(models, fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create predictions for each model and decide the final outcome by majority voting\n",
    "try:\n",
    "    predictions = pkl.load(open('pickles/majority_pred.pkl', 'rb'))\n",
    "except:\n",
    "    predictions = np.zeros(test_data.shape[0])\n",
    "    for i in range(0, len(models)):\n",
    "        predictions += models[i].predict(test_data[:, 1:])\n",
    "    with open('pickles/majority_pred.pkl', 'wb') as fl:\n",
    "        pkl.dump(predictions, fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create predictions for each model and decide the final outcome by majority voting\n",
    "try:\n",
    "    svc_pred = pkl.load(open('pickles/majority_svc_pred.pkl', 'rb'))\n",
    "except:\n",
    "    svc_pred = np.zeros(test_data.shape[0])\n",
    "    for i in range(0, len(models)):\n",
    "        svc_pred += models[i].predict(test_data[:, 1:])\n",
    "    with open('pickles/majority_svc_pred.pkl', 'wb') as fl:\n",
    "        pkl.dump(svc_pred, fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voted_result = np.zeros(len(svc_pred))\n",
    "for i, agg in enumerate(svc_pred):\n",
    "    if agg > m/2:\n",
    "        voted_result[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voted_result = np.zeros(len(predictions))\n",
    "for i, agg in enumerate(predictions):\n",
    "    if agg > m/2:\n",
    "        voted_result[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print classification_report(test_data[:,0], voted_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes = slice_graph_by_year(start_date, start_date-7, GCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cv.train_test_split(train_data[:,1:], train_data[:,0], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "2142685L*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = cv.cross_val_score(ll, train_data[:,1:], train_data[:,0], cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a cross validation experiment on the logistic classifier based on the years 2000 - 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print classification_report(y[test], classifier.predict(X[test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier.tree_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
